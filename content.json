{"pages":[{"title":"about","text":"","link":"/about/index.html"}],"posts":[{"title":"python编程","text":"变量和简单类型单行注释和多行注释 通常而言，合理的代码注释应该占源代码的1/3左右 变量弱类型语言两个典型特征 变量无需声明即可直接赋值：对于一个不存在的变量赋值就相当于定义了一个新变量 变量的数据类型可以动态的改变：同一个变量可以一会被赋值整数值，一会为字符串","link":"/2021/08/01/python%E7%BC%96%E7%A8%8B/"},{"title":"基于前馈神经网络对iris数据集分类","text":"分类问题（3类，数据网站有数据的详细描述） 数据源http://archive.ics.uci.edu/ml/datasets/Iris 用BP算法训练单隐层前馈神经网络，实现Iris数据分类 数据划分：训练和测试数据集划分参考网站上论文的划分 sklearn.datasets中含有iris的数据集 加载iris数据集并显示数据集格式 123from sklearn.datasets import load_irisiris = load_iris()print(iris) 数据集格式：观察结构为字典，存储在iris中 {‘data’: array([[5.1, 3.5, 1.4, 0.2], ​ [4.9, 3. , 1.4, 0.2], ​ [4.7, 3.2, 1.3, 0.2], ​ [4.6, 3.1, 1.5, 0.2], …… ​ [5.9, 3. , 5.1, 1.8]]), ‘target’: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ​ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ​ 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ​ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ​ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ​ 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ​ 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), ‘frame’: None, ‘target_names’: array([‘setosa’, ‘versicolor’, ‘virginica’], dtype=’&lt;U10’),’DESCR’:……’filename’: ‘C:\\Users\\zky666\\.conda\\envs\\pytorch\\lib\\site-packages\\sklearn\\datasets\\data\\iris.csv’} 调用pandas库，读取iris中data数据，存储在pandas中DataFrame数据结构中，列标签分别为：Sepal_Length,Sepal_Width,Petal_length,Petal_Width 1iris_d = pd.DataFrame(iris['data'], columns=['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width']) DataFrame的数据格式为： ​ Sepal_Length Sepal_Width Petal_Length Petal_Width 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 .. … … … … 145 6.7 3.0 5.2 2.3 146 6.3 2.5 5.0 1.9 147 6.5 3.0 5.2 2.0 148 6.2 3.4 5.4 2.3 149 5.9 3.0 5.1 1.8 按照种类，将每个品种的花单独划分为一个分类 12345iris_d['Species'] = iris.targetiris_class1 = iris_d[iris_d[&quot;Species&quot;]==0]iris_class2 = iris_d[iris_d[&quot;Species&quot;]==1]iris_class3 = iris_d[iris_d[&quot;Species&quot;]==2] Sepal_Length Sepal_Width Petal_Length Petal_Width Species 0 5.1 3.5 1.4 0.2 0 1 4.9 3.0 1.4 0.2 0 2 4.7 3.2 1.3 0.2 0 .. … … … … … 148 6.2 3.4 5.4 2.3 2 149 5.9 3.0 5.1 1.8 2 [150 rows x 5 columns] Sepal_Length Sepal_Width Petal_Length Petal_Width Species 0 5.1 3.5 1.4 0.2 0 1 4.9 3.0 1.4 0.2 0 …… 48 5.3 3.7 1.5 0.2 0 49 5.0 3.3 1.4 0.2 0 分析参数两两之间的关系 1234567891011import itertoolsplt.figure(figsize=(15, 10))t = 1for i, j in list(itertools.combinations(['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width'], 2)): plt.subplot(2, 3, t) plt.scatter(iris_class1[i], iris_class1[j], 15 , c = 'r') plt.scatter(iris_class2[i], iris_class2[j], 15 , c = 'g') plt.scatter(iris_class3[i], iris_class3[j], 15 , c = 'b') t += 1 plt.title(str(i) + ' + ' + str(j))plt.show() 结果： 结论： 只有Sepal_Length和Sepal_Width不能很好的分类，其他几项还算是不错 分析三个参数之间的关系 12345678910111213141516171819202122232425262728import itertoolsfrom mpl_toolkits.mplot3d import Axes3Dfig = plt.figure(figsize=(7, 5))ax = Axes3D(fig)ax.scatter(iris_class1['Sepal_Length'], iris_class1['Sepal_Width'], iris_class1['Petal_Length'], c = 'r')ax.scatter(iris_class2['Sepal_Length'], iris_class2['Sepal_Width'], iris_class1['Petal_Length'], c = 'g')ax.scatter(iris_class3['Sepal_Length'], iris_class3['Sepal_Width'], iris_class1['Petal_Length'], c = 'b')fig = plt.figure(figsize=(7, 5))ax = Axes3D(fig)ax.scatter(iris_class1['Sepal_Length'], iris_class1['Sepal_Width'], iris_class1['Petal_Width'], c = 'r')ax.scatter(iris_class2['Sepal_Length'], iris_class2['Sepal_Width'], iris_class1['Petal_Width'], c = 'g')ax.scatter(iris_class3['Sepal_Length'], iris_class3['Sepal_Width'], iris_class1['Petal_Width'], c = 'b')fig = plt.figure(figsize=(7, 5))ax = Axes3D(fig)ax.scatter(iris_class1['Sepal_Length'], iris_class1['Petal_Length'], iris_class1['Petal_Width'], c = 'r')ax.scatter(iris_class2['Sepal_Length'], iris_class2['Petal_Length'], iris_class1['Petal_Width'], c = 'g')ax.scatter(iris_class3['Sepal_Length'], iris_class3['Petal_Length'], iris_class1['Petal_Width'], c = 'b')fig = plt.figure(figsize=(7, 5))ax = Axes3D(fig)ax.scatter(iris_class1['Sepal_Width'], iris_class1['Petal_Length'], iris_class1['Petal_Width'], c = 'r')ax.scatter(iris_class2['Sepal_Width'], iris_class2['Petal_Length'], iris_class1['Petal_Width'], c = 'g')ax.scatter(iris_class3['Sepal_Width'], iris_class3['Petal_Length'], iris_class1['Petal_Width'], c = 'b')plt.show() Sepal_Length + Sepal_Width + Petal_Length： Sepal_Length + Sepal_Width + Petal_Width： Sepal_Length + Petal_Length + Petal_Width： Sepal_Width + Petal_Length + Petal_Width： 结论：其中Sepal_Length + Petal_Length + Petal_Width和Sepal_Width + Petal_Length + Petal_Width分类效果较好 综上所述Petal_Length + Petal_Width在分类中相对有较大影响，因此在后续的数据处理中可能会对原始数据进行降维处理 利用PCA进行降维 调用skleaen.decomposition中PCA函数进行降维 123transfer_1 = PCA(n_components=2)iris_d = transfer_1.fit_transform(iris_d)print(iris_d) 划分训练集与测试集 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率），并将前120行作为训练集，后30行作为测试集 12345678910111213141516iris_x_numpy = np.array(iris_d)# print(iris_d)np.random.seed(120)np.random.shuffle(iris_x_numpy)x_train = iris_x_numpy[:-30]x_test = iris_x_numpy[-30:]x_train_tensor = torch.tensor(x_train)x_test_tensor = torch.tensor(x_test)# print(iris_x_tensor)iris_numpy_y = np.array(iris.target)np.random.seed(120)np.random.shuffle(iris_numpy_y)y_train = iris_numpy_y[:-30]y_test = iris_numpy_y[-30:]y_train_tensor = torch.tensor(y_train)y_test_tensor = torch.tensor(y_test) 将pandas.DataFrame 转成 torch.tensor 1234x_train_tensor = torch.tensor(x_train)x_test_tensor = torch.tensor(x_test)y_train_tensor = torch.tensor(y_train)y_test_tensor = torch.tensor(y_test) 将Tensor转换为Variable，装载梯度信息 12345x_train_V = Variable(x_train_tensor)x_test_V = Variable(x_test_tensor)y_train_V = Variable(y_train_tensor)y_test_V = Variable(y_test_tensor)print(&quot;y_test_V&quot;, y_test_V) 利用pytorch框架构建BP神经网络模型 12345net = torch.nn.Sequential( torch.nn.Linear(2, 10), torch.nn.ReLU(), torch.nn.Linear(10, 3),) 选择损失值求解算法 1loss_func = torch.nn.CrossEntropyLoss() # the target label is NOT an one-hotted 构造优化器optimizer 123# optimizer = torch.optim.SGD(net.parameters(), lr=0.5) # 随机梯度下降optimizer = torch.optim.ASGD(net.parameters(), lr=0.5, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0) # 随机梯度下降 训练模型 1234567891011lost_step = []accyracy_list = []for t in range(100): out = net(x_train_V.float()) # input x and predict based on x loss = loss_func(out, y_train_V.long()) # must be (1. nn output, 2. target), the target label is NOT one-hotted print(&quot;loss:&quot;, loss.detach().numpy()) lost_step.append(loss) optimizer.zero_grad() # clear gradients for next train loss.backward() # backpropagation, compute gradients optimizer.step() # apply gradients 检验模型，计算准确率+画图 12345678910111213141516171819202122232425262728293031323334if t % 10 == 0: # plot and show learning process plt.cla() prediction = torch.max(out, 1)[1] print(prediction) pred_y = prediction.data.numpy() print(pred_y) target_y = y_train_V.data.numpy() # print(x) print(x_train_V.data.numpy()[:, 0]) x1_min, x1_max = x_train_V[:, 0].min(), x_train_V[:, 0].max() x2_min, x2_max = x_train_V[:, 1].min(), x_train_V[:, 1].max() plt.scatter(x_train_V.data.numpy()[:, 0], x_train_V.data.numpy()[:, 1], c=pred_y, s=100, lw=0, cmap='RdYlGn') # plt.legend() plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) y_test_pred = net(x_test_V.float()) prediction_y = torch.max(y_test_pred, 1)[1] pred_y_test = prediction_y.data.numpy() print(&quot;pred_y_test:&quot;, pred_y_test) y_test_target = y_test_V.data.numpy() print(&quot;y_test_target:&quot;, y_test_target) accuracy = float((pred_y_test == y_test_target).astype(int).sum()) / float(y_test_target.size) accyracy_list.append(accuracy) print(accuracy) plt.text(2.3, -1.5, 'Accuracy=%.2f' % accuracy, fontdict={'size': 15, 'color': 'red'}) plt.pause(0.1) 当lr = 0.2时 训练10次： 训练20次： 训练30次： 训练40次： 训练90次： 训练100次： 损失值与测试集准确率变化曲线 当lr = 0.5时 第10次训练： 第20次训练： 第30次训练： 第50次训练： 第100次训练： 损失值与测试集准确率变化曲线 动态更新学习率： 1optimizer = torch.optim.ASGD(net.parameters(), lr=0.5, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0) 第10次训练： 第20次训练： 第30次训练： 第100次训练： 损失值与测试集准确率变化曲线：","link":"/2021/07/31/%E5%9F%BA%E4%BA%8E%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9iris%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E7%B1%BB/"},{"title":"基于对抗网络生成数字图像","text":"基于生成对抗网络生成数字图像已知，采用卷积神经网络构建的生成对抗网络会比采用全连接网络的准确率高，所以会按照卷积网络、生成对抗网络、利用对抗网络生成数字图像的顺序进行介绍 参考资料： https://www.jianshu.com/p/1ea2949c0056 https://www.jianshu.com/p/fbcada37ca45 https://www.jianshu.com/p/77627ada2935 Convolutional Neural Networks (LeNet) - DeepLearning 0.1 documentation. DeepLearning 0.1. LISA Lab. [31 August 2013]. https://zhuanlan.zhihu.com/p/33752313 王坤峰，荀超，段艳杰等.生成式对抗网络GAN的研究进展与展望[J].自动化学报.2017 卷积神经网络卷积神经网络的理解： ​ 卷积神经网络的架构 全连接与稀疏连接假设一个神经网络中有m个输入、n个输出。那么对于全连接的矩阵相乘则需要mn个参数。如果输出的连接数被设定为j个，那么采用稀疏连接则只需要jn个参数。在许多情景中，在连接数被设定为j，且j比m要小得多的情况下，机器学习应用的速度获得大幅度的提升，并且仍然能保持较好的效果。 让我们从下图中对比一下全连接与稀疏连接的神经网络。 ​ 全连接的神经网络 ​ 稀疏连接的神经网络 稀疏连接的方法可以使神经网络的连接结构更加简单，同时以更高效的方法来描述变量之间的关系。对比上述两幅图，从输入的角度（自下而上）来看，x3输入在全连接中与所有的输出单元相连接。而在稀疏连接中x3仅仅与s2、s3、s4相连接。 ​ 自上而下从输出看输入 反过来从输出来看输入也是如此。 也许对于卷积网络，其稀疏连接方式的感受野无法设计整个输入，但是当卷积层数增加的时候（深层卷积网络）其单个输出的感受野还是可以涉及到整个输入的。 ​ 多层稀疏连接的感受野 卷积网络通过采用稀疏连接的方法减少了需要存储的参数（权重）的数量，减少了机器学习模型所需要的存储空间，从而提升了模型的统计效率。从计算方面来看，较少的参数数量意味着计算输出时需要更少的参数，从而计算效率也得到大幅提升。 参数共享参数共享是紧接着稀疏连接而来的。在模型中多个函数使用相同的参数则是参数共享。这个共享的参数通常是权重，即共享权重（Shared Weight）。在传统的神经网络中，每个权重被使用一次。而使用共享权重，一个输入位置的参数值也会被应用在其他的输入位置。在卷积网络中，通过参数共享，一个卷积核内的参数会被应用在输入的所有位置。 ​ 参数共享示意图 上图中黑色的箭头表示了在两个不同的模型中使用了特殊参数的连接。上图中，黑色箭头表示在卷积模型中对3个元素核的中间元素的使用。由于参数共享，因此这个单独的参数被用于所有的输入的位置。而在下图中，这个单独的黑色的箭头表示在全连接模型中对权重矩阵的中间元素的使用，下面这个模型没有参数共享，所以参数只使用了一次。 等变表示对于卷积来说，参数共享的特殊形式使得神经网络层具有了对平移等变（Equivariance）的性质。一个函数满足输入改变，那么输出也以同样的方式改变这一个性质，那么这个函数就是等变的。即输入发生变化输出也相应发生同样的变化。 如果f(g(x))=g(f(x))，那么函数f(x)对于变换g具有等变性。在卷积网络中，令g是输入的任意平移函数，那么卷积函数对于g具有等变性。举例，令I表示图像在整数坐标上的亮度函数，g表示图像函数的变换函数，即把一个图像映射到另一个图像函数的函数。令I’=g(I)，图像函数I’满足I’(x,y)=I(x-1,y)。上述函数所做的变换就是将I中的每一个像素均向右移动一个单位。如果先对图像I施加变换，再进行卷积操作f，结果等同于对图像I的卷积施加变换。也就是说，如果图像中的目标发生了一定的位移之后，卷积输出的表达也会产生相同的位移。这个特征对于作用在一个相对小区域的算子十分有用。 卷积网络的经典结构卷积网络的层结构简单的卷积神经网络由一系列不同的层构成，每个层将上一层的一组隐藏层的输出通过一个可微的函数产生一组新的隐藏层的输出。 一个典型的卷积网络有几种不同的层构成： 1、卷积层（Convolutional Layer，CONV） 2、ReLU（Rectified Linear Unit） ReLU(x)=max(0,x) 3、池化层（Pooling Layer，POOL） 4、全连接层（Fully-Connected Layer，FC） 全连接层与普通的神经网络相同。 这些层极其具体的作用如下表所示： 名称 作用 INPUT 输入层：如，以图像的像素的值作为输入 CONV 卷积层：卷积层连接输入的一小块区域，并计算卷积核与之对应的输入区域之间的点乘作为卷积层的输出 ReLU 激活函数：将CONV层中输出的每个元素通过一个非线性激活函数 POOL 池化层：在空间上（Height和Width）执行降采样操作 FC 全连接层：在分类中，将计算每个类别对应的分数，和传统神经网络一样，全连接层的每个神经元与前一层的所有输出相连 上述从INPUT到FC是一个典型的卷积网络的层结构。 CIFAR-10数据集共有60000张彩色图像，这些图像是32*32，分为10个类，每类6000张图。 ​ CIFAR-10数据集示例 以CIFAR-10数据集作为输入来讲解一下卷积网络的各个层的功能： 名称 作用 INPUT 输入层：输入一张大小为32323的3通道RGB图像 CONV 卷积层：如CONV层有12个卷积核，则通过CONV层输出的尺寸为323212 ReLU 激活函数：保持图像的尺寸为323212 POOL 池化层：以22的小窗做降采样操作，特征图的尺寸缩小到1616*12 FC 全连接层：在分类中，输出的尺寸为1110，也就是CIFAR-10中10个类别分别对应的分数 各种卷积网络的结构模式其实，目前很多的卷积网络都是根据一种层级结构的模式进行不同的堆叠。最常见的网络的结构是将 CONV-ReLU堆叠若干遍之后，紧接着一个POOL池化层。然后再重复上述的结构，直到图像在空间上转换成为一个较小的尺寸。最后使用一个全连接层转换为输出。 让我们以一个正则表达式来表示上述的模式： INPUT -&gt; [[CONV -&gt; RELU] * N -&gt; POOL ? ]M -&gt; [FC-&gt;RELU] * K -&gt; FC 其中， N代表重复N次，？代表0或1次，一般来说0&lt;N≤3，M≥0,0&lt;K≤3。 ​ VGGNet (2014) 卷积层的实现卷积层的参数有一组可以学习的卷积核(Kernel)/滤波器（Filter）构成。每个卷积核在空间上是尺寸较小，穿过输入集的整个深度，如下图所示： ​ 一个卷积网络的示意图 卷积网络的第一层的卷积核尺寸通常为333（宽3个像素 高3个像素 深度为通道数是3的RGB图像）或553。在前向传播的过程中，在输入图像上沿着高和宽的方向滑动各个卷积核/滤波器（滤波器是通过向量来表示对输入进行卷积操作的权重），并在所有的位置上面计算卷积核与输入的点乘。当完成沿着宽和高滑动卷积核之后，会得到一个二维的激活映射（Activation Map），这个激活映射也被称为特征映射（Feature Map）或是特征图。特征图的含义是其在每个空间位置上输入对于卷积核的响应。 ​ 滑动卷积核/滤波器得到特征映射 卷积层上的每个卷积核都会生成一个激活特征映射，将这些特征映射沿着深度的方向排列起来并作为卷积层的输出。 比如一个553的滤波器在32323的图像上沿着宽和高滑动，遍历空间内所有的点之后生成的特征图为28281。如果使用3个这样的滤波器/卷积核进行操作之后，将会生成3个28281的特征映射。所以卷积层最终的输出大小为28283。 通过3个滤波器得到的3层特征映射堆叠 在卷积网络中堆叠CONV-RELU这样的结构，卷积核/滤波器的深度要与输入的特征图的深度一致。也就是说，后一个卷积层的卷积核/滤波器大小需要与前一个卷积层输出的维度一致。 ​ 可视化卷积网络 通过观察上述卷积网络的特征图的输出，我们可以发现，随着网络的层数的不断加深，特征图上的响应在表达语义的层面上不断加深。最初的层提取了低层特征（Low-Level Feature），而此后的卷积层在低层特征的基础上产生了具有语义的图形和纹理。最后的卷积层对明确语义的目标产生强烈的响应，也就是说其抽取了图像的高层特征。 卷积层的空间排布在卷积网络中，输出的特征图的尺寸由深度（Depth）、步长（Stride）和零值填充（Zero-Padding）三个超参数决定。 对于输出图的深度这个超参数，其由使用的卷积核/滤波器的数量决定，每个卷积核都负责从输入图像中提取出不同的信息（见下图）。 ​ 不同的卷积操作对应的卷积核以及卷积输出 在卷积网络中对于同一个输入，为了提取不同的特征，需要使用不同的卷积核操作，并且将响应的特征映射堆叠排列起来作为输出。 然后就是滑动卷积核的步长。当滑动卷积核的步长为1的时候，卷积核/滤波器每次移动1个像素的位置。当步长为2的时候，卷积核每次移动2个像素的位置…步长越大，生成的特征映射的空间尺寸就越小。 最后是零值填充。有的时候，为了使用更深的卷积网络，此时则不希望特征映射在卷积的过程中尺寸下降地太快，因此会在输入的边缘使用零值填充来增大输入尺寸。 假设当前卷积层的输入图像尺寸为W、卷积神经元的感受野为F、步长S、边缘零值填充数量为P，则输出特征映射的尺寸为： ​ 经过卷积层的特征图尺寸 数据输入层该层要做的处理主要是对原始图像数据进行预处理，其中包括： 去均值：把输入数据各个维度都中心化为0，如下图所示，其目的就是把样本的中心拉回到坐标系原点上。 归一化：幅度归一化到同样的范围，如下所示，即减少各维度数据取值范围的差异而带来的干扰，比如，我们有两个维度的特征A和B，A范围是0到10，而B范围是0到10000，如果直接使用这两个特征是有问题的，好的做法就是归一化，即A和B的数据都变为0到1的范围。 PCA/白化：用PCA降维；白化是对数据各个特征轴上的幅度归一化 去均值与归一化效果图： 去相关与白化效果图： 把卷积层输出结果做非线性映射。 激活函数有： sigmoid：在两端斜率接近于0，梯度消失。 ReLu：修正线性单元，有可能出现斜率为0，但概率很小，因为mini-batch是一批样本损失求导之和。 TIPS: CNN慎用sigmoid！因为会映射到0-1，和图像的特征不太符合 首先试RELU，因为快，但要小心点。 如果RELU失效，请用 Leaky ReLU或者Maxout。 某些情况下tanh倒是有不错的结果，但是很少。 池化层也叫下采样层，具有特征不变性。 为了减少表达空间的尺寸，卷积网络的连续的卷积层之间往往会周期性地插入池化层。池化层能逐渐减少表达空间的尺寸，降低参数数量和计算开销，并控制卷积网络减少过拟合。 ​ 最大池化图解 在卷积网络中，最常见的池化操作是最大池化（Max Pooling），也就是取视野范围内的最大值。对上图最大池化示意图而言，其输入特征图的尺寸是44，步长为2的池化操作后，得到22的输出特征图。在池化窗口大小是2的是，上图中被分为四种颜色的四个区域，每个区域对应输出特征图的一个像素，对每个窗口取其中的最大值作为输出特征图相应位置的值。 池化窗口的选取通常是2或3，如果窗口大小过大则会对特征图的信息造成破坏。除了最大池化之外，还有平均池化（Average Pooling）和L2-Norm池化。 ​ 特征图池化操作输出的效果 最大池化操作的反向传播形式很简单：将梯度沿着正向传播的过程中最大值的路径向下传递。池化层的正向传递通常会保留最大激活单元下标，作为反向传递时候的传播路径。 CNN的优缺点优点： 共享卷积核，优化计算量。 无需手动选取特征，训练好权重，即得特征。 深层次的网络抽取图像信息丰富，表达效果好。 保持了层级网络结构。 不同层次有不同形式与功能。 缺点： 需要调参，需要大样本量，GPU等硬件依赖。 物理含义不明确。 与NLP/Speech共性： 都存在局部与整体的关系，由低层次的特征经过组合，组成高层次的特征，并且得到不同特征之间的空间相关性。 卷积神经网络之典型CNN结构 LeNet，这是最早用于数字识别的CNN AlexNet， 2012 ILSVRC比赛远超第2名的CNN，比 LeNet更深，用多层小卷积层叠加替换单大卷积层。 ZF Net， 2013 ILSVRC比赛冠军 GoogLeNet， 2014 ILSVRC比赛冠军 VGGNet， 2014 ILSVRC比赛中的模型，图像识别略差于GoogLeNet，但是在很多图像转化学习问题(比如object detection)上效果奇好 卷积神经网络常用的框架Caffe 源于Berkeley的主流CV工具包，支持C++,python,matlab Model Zoo中有大量预训练好的模型供使用 Torch Facebook用的卷积神经网络工具包 通过时域卷积的本地接口，使用非常直观 定义新网络层简单 TensorFlow Google的深度学习框架 TensorBoard可视化很方便 数据和模型并行化好，速度快. 生成对抗网络GANGAN的基本原理GAN 的核心思想来源于博弈论的纳什均衡。它设定参与游戏双方分别为一个生成器(Generator)和一个判别器 (Discriminator), 生成器的目的是尽量去学习真实的数据分布 ,而判别器的目的是尽量正确判别输入数据是来自真实数据还是来自生成器 ;为了取得游戏胜利 , 这两个游戏参与者需要不断优化 ,各自提高自己的生成能力和判别能力 ,这个学习优化过程就是寻找二者之间的一个纳什均衡。GAN的计算流程与结构如图 2 所示。任意可微分的函数都可以用来表示 GAN 的生成器和判别器 由此 ,我们用可微分函数D和 G来分别表示判别器和生成器 ,它们的输入分别为真实数据x和随机变量 z.G(z)则为由G 生成的尽量服从真实数据分布pdata的样本。如果判别器的输入来自真实数据 ,标注为1.如果输入样本为 G(z), 标注为 0. 这里 D 的目标是实现对数据来源的二分类判别 :真 ( 来源于真实数据x 的分布 )或者伪 ( 来源于生成器的伪数据 G(z)),而G的目标是使自己生成的伪数G(z)在D上的表现 D(G(z))和真实数据x在D上的表现 D(x)一致 ,这两个相互对抗并迭代优化的过程使得D和G 的性能不断提升 ,当最终D的判别能力提升到一定程度 ,并且无法正确判别数据来源时 ,可以认为这个生成器G已经学到了真实数据的分布。 手写字的例子来进行进一步窥探GAN的结构。 我们现在拥有大量的手写数字的数据集，我们希望通过GAN生成一些能够以假乱真的手写字图片。主要由如下两个部分组成： 定义一个模型来作为生成器（图中蓝色部分Generator），能够输入一个向量，输出手写数字大小的像素图像。 定义一个分类器来作为判别器（图三中红色部分Discriminator）用来判别图片是真的还是假的（或者说是来自数据集中的还是生成器中生成的），输入为手写图片，输出为判别图片的标签。 训练方法基本流程如下： 训练生成器之后达到（c）样本状态，此时生成器分布相比之前，逼近了真实样本分布。 经过多次反复训练迭代之后，最终希望能够达到（d）状态，生成样本分布拟合于真实样本分布，并且判别器分辨不出样本是生成的还是真实的（判别概率均为0.5）。也就是说我们这个时候就可以生成出非常真实的样本了，目的达到。 训练相关理论包含min，max的公式 判别器在这里是一种分类器，用于区分样本的真伪，因此我们常常使用交叉熵（cross entropy）来进行判别分布的相似性，交叉熵公式如下图所示： Tips: 公式中pi和qi为真实的样本分布和生成器的生成分布。由于交叉熵是非常常见的损失函数，这里默认大家都较为熟悉，就不进行赘述了。 在当前模型的情况下，判别器为一个二分类问题，因此可以对基本交叉熵进行更具体地展开如下图所示： Tips: 其中，假定y1为正确样本分布，那么对应的（1-y1）就是生成样本的分布。D表示判别器，则D(x1)表示判别样本为正确的概率，(1-D(x1)) 则对应着判别为错误样本的概率。这里仅仅是对当前情况下的交叉熵损失的具体化。相信大家也还是比较熟悉。 对于GAN中的样本点 xi ，对应于两个出处，要么来自于真实样本，要么来自于生成器生成的样本 x^ ~G(z) ( 这里的z是服从于投到生成器中噪声的分布)。 其中，对于来自于真实的样本，我们要判别为正确的分布 yi。来自于生成的样本我们要判别其为错误分布（1-yi）。将上面式子进一步使用概率分布的期望形式写出（为了表达无限的样本情况，相当于无限样本求和情况），并且让yi 为 1/2 且使用G(z)表示生成样本可以得到如下图的公式： 现在我们再回过头来对比原本的的minmax公式，发现他们其实就是同一个东西 生成数字图像采用的数据集因为GANS中超参数的设置非常非常麻烦，同样也需要很多的训练epoch。为了加快训练速度，这里使用MNIST数据集，拥有60，000个训练集和10，000测试集。每个图片中包含一个数字（0-9，背景为黑色，数字为白色）。这个数据集通过标准神经网络的训练已经可以达到超过99%的准确率。 这里使用pytorch中自带的数据集工具进行对数据的提取： 原始图像： 随机分布生成的噪声： 定义卷积判别网络： 定义卷积生成网络 定义损失函数 定义优化器 定义训练函数 实验结果： 早期： 最后的结果： 损失值： Iter: 250, D: 1.057, G:2.979 Iter: 500, D: 0.8309, G:1.727 Iter: 750, D: 0.918, G:1.692 Iter: 1000, D: 1.195, G:0.831 Iter: 1250, D: 0.9382, G:1.559 Iter: 1500, D: 1.344, G:1.697 Iter: 1750, D: 1.01, G:1.106 Iter: 2000, D: 1.214, G:1.769 Iter: 2250, D: 0.9676, G:1.234 Iter: 2500, D: 1.056, G:0.9057 Iter: 2750, D: 1.062, G:1.124 Iter: 3000, D: 1.158, G:0.8272 Iter: 3250, D: 0.9431, G:1.994 Iter: 3500, D: 1.112, G:1.288 Iter: 3750, D: 0.9812, G:0.9615 Iter: 4000, D: 1.125, G:1.248 Iter: 4250, D: 0.8623, G:1.461 Iter: 4500, D: 1.029, G:1.31 Iter: 4750, D: 0.8219, G:1.661 Iter: 5000, D: 0.9472, G:1.26 Iter: 5250, D: 0.9054, G:1.3 Iter: 5500, D: 0.8741, G:2.153 Iter: 5750, D: 0.9253, G:1.002 Iter: 6000, D: 0.9568, G:1.278 Iter: 6250, D: 0.9611, G:1.35 Iter: 6500, D: 0.8447, G:1.67 Iter: 6750, D: 0.9014, G:1.341 Iter: 7000, D: 0.9592, G:1.282 Iter: 7250, D: 0.985, G:1.329 Iter: 7500, D: 0.9468, G:1.517 Iter: 7750, D: 1.003, G:1.364 注：以上实验结果是已经得出的较优模型损失值等得出的较好结果 去掉卷积层，实现较为简单的生成对抗网络 改变网络结构为： 初始实验结果： 最终实验结果： 损失值： Iter: 250, D: 1.511, G:0.8354 Iter: 500, D: 1.359, G:0.612 Iter: 750, D: 1.389, G:2.019 Iter: 1000, D: 1.147, G:2.05 Iter: 1250, D: 0.833, G:2.16 Iter: 1500, D: 0.9256, G:1.52 Iter: 1750, D: 1.087, G:1.98 Iter: 2000, D: 0.9269, G:1.244 Iter: 2250, D: 1.108, G:1.061 Iter: 2500, D: 1.057, G:1.093 Iter: 2750, D: 1.115, G:1.932 Iter: 3000, D: 0.9873, G:1.402 Iter: 3250, D: 0.7824, G:1.464 Iter: 3500, D: 0.9784, G:1.319 Iter: 3750, D: 1.112, G:1.123 改变FC层网络结构为：（0&lt;K≤3。） 初始实验结果： 最终实验结果： 损失值： Iter: 250, D: 0.9404, G:1.127 Iter: 500, D: 0.8368, G:1.118 Iter: 750, D: 0.8559, G:0.8823 Iter: 1000, D: 1.018, G:1.133 Iter: 1250, D: 0.8485, G:1.997 Iter: 1500, D: 0.6933, G:1.756 Iter: 1750, D: 0.7199, G:1.98 Iter: 2000, D: 0.7108, G:1.534 Iter: 2250, D: 0.7834, G:2.019 Iter: 2500, D: 0.7777, G:1.758 Iter: 2750, D: 0.8702, G:1.776 Iter: 3000, D: 0.7444, G:1.677 Iter: 3250, D: 0.769, G:1.605 Iter: 3500, D: 1.103, G:1.76 Iter: 3750, D: 0.6795, G:2.354 Iter: 4000, D: 0.7162, G:1.787 Iter: 4250, D: 0.6472, G:2.09 Iter: 4500, D: 0.6834, G:2.19 Iter: 4750, D: 0.5053, G:2.736 Iter: 5000, D: 0.6162, G:2.434 Iter: 5250, D: 0.5765, G:3.15 Iter: 5500, D: 0.6916, G:2.053 Iter: 5750, D: 0.6257, G:2.553 Iter: 6000, D: 0.5586, G:2.937 Iter: 6250, D: 0.7283, G:2.733 Iter: 6500, D: 0.5604, G:3.598 Iter: 6750, D: 0.7311, G:1.48 Iter: 7000, D: 0.5016, G:3.57 Iter: 7250, D: 0.3809, G:3.069 Iter: 7500, D: 0.5193, G:2.837 更改模型的依据： GPU加速： 方法一：直接调用cuda()方法 12345678910real_data = Variable(x).cuda() *#* *真实数据*g_fake_seed = Variable(sample_noise).cuda()fake_images = G_net(g_fake_seed).cuda() *#* *生成的假的数据*D_DC = build_dc_classifier().cuda()for x, _ in train_data: X = X.cuda() 方法二：可以分别调用多块GPU 1234device = torch.device('cuda:0')X = X.to(device)net.to('cuda:0')b=torch.zeros(x.size(0),self.out_num_caps,self.in_num_caps).to('cuda:0')","link":"/2021/07/28/%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%94%9F%E6%88%90%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F/"}],"tags":[{"name":"python","slug":"python","link":"/tags/python/"},{"name":"深度学习","slug":"深度学习","link":"/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"前馈神经网络","slug":"前馈神经网络","link":"/tags/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"CNN","slug":"CNN","link":"/tags/CNN/"}],"categories":[{"name":"智能科技","slug":"智能科技","link":"/categories/%E6%99%BA%E8%83%BD%E7%A7%91%E6%8A%80/"}]}