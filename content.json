{"pages":[{"title":"about","text":"","link":"/about/index.html"}],"posts":[{"title":"Ubuntu死机解决方法汇总","text":"作者：程序员联盟链接：https://www.jianshu.com/p/36fb9eed82a3來源：简书 为什么不建议强制关机 如果长按电源按键强制关机，有可能损坏硬件或者丢失数据，甚至导致磁盘坏道！ 其实, 大部分时候的死机是假死, 不是真死… 有时候鼠标还能动呢。 还有一个原因: 对于平时忠贞不二的电脑, 我们怎么可以用强制关机这么”家暴”的手段呢… 必须要温柔。 可尝试的解决方法1. 进入TTY终端 Ctrl+Alt+F1进入TTY1终端字符界面, 输入用户名和密码以登录 输入top命令, 找到可能造成假死的进程, 用kill命令结束掉进程。然后Ctrl+Alt+F7回到桌面 2. 直接注销用户Ctrl+Alt+F1进入TTY1终端字符界面, 输入用户名和密码以登录。 然后执行以下的任意一个命令注销桌面重新登录。 1sudo pkill Xorg 或者 1sudo restart lightdm 3. 底层方法如果上面两种方法不成功, 那有可能是比较底层的软件出现问题。 可以试试 :** reisub 方法**。 说具体一点, 是一种系统请求, 直接交给内核处理。 键盘上一般都有一个键SysRq, 和PrintScreen(截屏)在一个键位上，这就是系统请求的键。 这个方法可以在死机的情况下安全地重启计算机, 数据不会丢失。 下面解释一下这个方法： 其实 SysRq是一种叫做系统请求的东西, 按住 Alt-Print 的时候就相当于按住了SysRq键，这个时候输入的一切都会直接由 Linux 内核来处理，它可以进行许多低级操作。 这个时候 reisub 中的每一个字母都是一个独立操作，分别表示： r : unRaw 将键盘控制从 X Server 那里抢回来 e : tErminate 给所有进程发送 SIGTERM 信号，让它们自己解决善后 i : kIll 给所有进程发送 SIGKILL 信号，强制他们马上关闭 s : Sync 将所有数据同步至磁盘 u : Unmount 将所有分区挂载为只读模式 b : reBoot 重启 魔法键组合 reisub 究竟该怎么用？如果某一天你的 Linux 死机了，键盘不听使唤了，Ctrl+Alt+F1 已经没有任何反应，该怎么办呢？ 使用“魔法键”：Alt+SysRq + r,e,i,s,u,b（确实很好背，就是单词 busier (英语”更忙”的意思)的倒写）。 好的，平时电脑那么正常，你自然也不会去按这些按钮。等到真的出事的时候，你把记在小纸条上的这些 tips 拿出来，然后在键盘上按，结果发现啥反应也没有，于是只能欲哭无泪了。 问题在于：究竟该怎么按这些按钮才会有效？首先，你的系统要支持这个功能，查看和开启的方法大家应该很熟悉了，网上也有很多说明，而且最幸运的是：Ubuntu 默认已经开启了这个功能。 接下来就是操作：马上你就会发现，同时按下+压根儿行不通！只会蹦出来一个屏幕截图窗口。所以，真正的做法应该是： 伸出你的左手，同时按住+键，别松开 右手先按一下，左手别松开，等1秒 右手按一下 R，左手别松开，等1秒 右手按一下 E，左手别松开。这时包括桌面在内，所有程序都会终止，你会看到一个黑乎乎的屏幕，稍微等一段时间 右手依次按下 I，S，U，B，左手别松开。每按一次都等那么几秒种，你会发现每按一次，屏幕上信息都会有所变化。最后按下B时，屏幕显示reset，这时你的左手可以松开了，等几秒钟，计算机就会安全重启。","link":"/2021/08/02/Ubuntu%E6%AD%BB%E6%9C%BA%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/"},{"title":"基于前馈神经网络对iris数据集分类","text":"分类问题（3类，数据网站有数据的详细描述） 数据源http://archive.ics.uci.edu/ml/datasets/Iris 用BP算法训练单隐层前馈神经网络，实现Iris数据分类 数据划分：训练和测试数据集划分参考网站上论文的划分 sklearn.datasets中含有iris的数据集 加载iris数据集并显示数据集格式 123from sklearn.datasets import load_irisiris = load_iris()print(iris) 数据集格式：观察结构为字典，存储在iris中 {‘data’: array([[5.1, 3.5, 1.4, 0.2], ​ [4.9, 3. , 1.4, 0.2], ​ [4.7, 3.2, 1.3, 0.2], ​ [4.6, 3.1, 1.5, 0.2], …… ​ [5.9, 3. , 5.1, 1.8]]), ‘target’: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ​ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ​ 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ​ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ​ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ​ 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ​ 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), ‘frame’: None, ‘target_names’: array([‘setosa’, ‘versicolor’, ‘virginica’], dtype=’&lt;U10’),’DESCR’:……’filename’: ‘C:\\Users\\zky666\\.conda\\envs\\pytorch\\lib\\site-packages\\sklearn\\datasets\\data\\iris.csv’} 调用pandas库，读取iris中data数据，存储在pandas中DataFrame数据结构中，列标签分别为：Sepal_Length,Sepal_Width,Petal_length,Petal_Width 1iris_d = pd.DataFrame(iris['data'], columns=['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width']) DataFrame的数据格式为： ​ Sepal_Length Sepal_Width Petal_Length Petal_Width 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 .. … … … … 145 6.7 3.0 5.2 2.3 146 6.3 2.5 5.0 1.9 147 6.5 3.0 5.2 2.0 148 6.2 3.4 5.4 2.3 149 5.9 3.0 5.1 1.8 按照种类，将每个品种的花单独划分为一个分类 12345iris_d['Species'] = iris.targetiris_class1 = iris_d[iris_d[&quot;Species&quot;]==0]iris_class2 = iris_d[iris_d[&quot;Species&quot;]==1]iris_class3 = iris_d[iris_d[&quot;Species&quot;]==2] Sepal_Length Sepal_Width Petal_Length Petal_Width Species 0 5.1 3.5 1.4 0.2 0 1 4.9 3.0 1.4 0.2 0 2 4.7 3.2 1.3 0.2 0 .. … … … … … 148 6.2 3.4 5.4 2.3 2 149 5.9 3.0 5.1 1.8 2 [150 rows x 5 columns] Sepal_Length Sepal_Width Petal_Length Petal_Width Species 0 5.1 3.5 1.4 0.2 0 1 4.9 3.0 1.4 0.2 0 …… 48 5.3 3.7 1.5 0.2 0 49 5.0 3.3 1.4 0.2 0 分析参数两两之间的关系 1234567891011import itertoolsplt.figure(figsize=(15, 10))t = 1for i, j in list(itertools.combinations(['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width'], 2)): plt.subplot(2, 3, t) plt.scatter(iris_class1[i], iris_class1[j], 15 , c = 'r') plt.scatter(iris_class2[i], iris_class2[j], 15 , c = 'g') plt.scatter(iris_class3[i], iris_class3[j], 15 , c = 'b') t += 1 plt.title(str(i) + ' + ' + str(j))plt.show() 结果： 结论： 只有Sepal_Length和Sepal_Width不能很好的分类，其他几项还算是不错 分析三个参数之间的关系 12345678910111213141516171819202122232425262728import itertoolsfrom mpl_toolkits.mplot3d import Axes3Dfig = plt.figure(figsize=(7, 5))ax = Axes3D(fig)ax.scatter(iris_class1['Sepal_Length'], iris_class1['Sepal_Width'], iris_class1['Petal_Length'], c = 'r')ax.scatter(iris_class2['Sepal_Length'], iris_class2['Sepal_Width'], iris_class1['Petal_Length'], c = 'g')ax.scatter(iris_class3['Sepal_Length'], iris_class3['Sepal_Width'], iris_class1['Petal_Length'], c = 'b')fig = plt.figure(figsize=(7, 5))ax = Axes3D(fig)ax.scatter(iris_class1['Sepal_Length'], iris_class1['Sepal_Width'], iris_class1['Petal_Width'], c = 'r')ax.scatter(iris_class2['Sepal_Length'], iris_class2['Sepal_Width'], iris_class1['Petal_Width'], c = 'g')ax.scatter(iris_class3['Sepal_Length'], iris_class3['Sepal_Width'], iris_class1['Petal_Width'], c = 'b')fig = plt.figure(figsize=(7, 5))ax = Axes3D(fig)ax.scatter(iris_class1['Sepal_Length'], iris_class1['Petal_Length'], iris_class1['Petal_Width'], c = 'r')ax.scatter(iris_class2['Sepal_Length'], iris_class2['Petal_Length'], iris_class1['Petal_Width'], c = 'g')ax.scatter(iris_class3['Sepal_Length'], iris_class3['Petal_Length'], iris_class1['Petal_Width'], c = 'b')fig = plt.figure(figsize=(7, 5))ax = Axes3D(fig)ax.scatter(iris_class1['Sepal_Width'], iris_class1['Petal_Length'], iris_class1['Petal_Width'], c = 'r')ax.scatter(iris_class2['Sepal_Width'], iris_class2['Petal_Length'], iris_class1['Petal_Width'], c = 'g')ax.scatter(iris_class3['Sepal_Width'], iris_class3['Petal_Length'], iris_class1['Petal_Width'], c = 'b')plt.show() Sepal_Length + Sepal_Width + Petal_Length： Sepal_Length + Sepal_Width + Petal_Width： Sepal_Length + Petal_Length + Petal_Width： Sepal_Width + Petal_Length + Petal_Width： 结论：其中Sepal_Length + Petal_Length + Petal_Width和Sepal_Width + Petal_Length + Petal_Width分类效果较好 综上所述Petal_Length + Petal_Width在分类中相对有较大影响，因此在后续的数据处理中可能会对原始数据进行降维处理 利用PCA进行降维 调用skleaen.decomposition中PCA函数进行降维 123transfer_1 = PCA(n_components=2)iris_d = transfer_1.fit_transform(iris_d)print(iris_d) 划分训练集与测试集 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率），并将前120行作为训练集，后30行作为测试集 12345678910111213141516iris_x_numpy = np.array(iris_d)# print(iris_d)np.random.seed(120)np.random.shuffle(iris_x_numpy)x_train = iris_x_numpy[:-30]x_test = iris_x_numpy[-30:]x_train_tensor = torch.tensor(x_train)x_test_tensor = torch.tensor(x_test)# print(iris_x_tensor)iris_numpy_y = np.array(iris.target)np.random.seed(120)np.random.shuffle(iris_numpy_y)y_train = iris_numpy_y[:-30]y_test = iris_numpy_y[-30:]y_train_tensor = torch.tensor(y_train)y_test_tensor = torch.tensor(y_test) 将pandas.DataFrame 转成 torch.tensor 1234x_train_tensor = torch.tensor(x_train)x_test_tensor = torch.tensor(x_test)y_train_tensor = torch.tensor(y_train)y_test_tensor = torch.tensor(y_test) 将Tensor转换为Variable，装载梯度信息 12345x_train_V = Variable(x_train_tensor)x_test_V = Variable(x_test_tensor)y_train_V = Variable(y_train_tensor)y_test_V = Variable(y_test_tensor)print(&quot;y_test_V&quot;, y_test_V) 利用pytorch框架构建BP神经网络模型 12345net = torch.nn.Sequential( torch.nn.Linear(2, 10), torch.nn.ReLU(), torch.nn.Linear(10, 3),) 选择损失值求解算法 1loss_func = torch.nn.CrossEntropyLoss() # the target label is NOT an one-hotted 构造优化器optimizer 123# optimizer = torch.optim.SGD(net.parameters(), lr=0.5) # 随机梯度下降optimizer = torch.optim.ASGD(net.parameters(), lr=0.5, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0) # 随机梯度下降 训练模型 1234567891011lost_step = []accyracy_list = []for t in range(100): out = net(x_train_V.float()) # input x and predict based on x loss = loss_func(out, y_train_V.long()) # must be (1. nn output, 2. target), the target label is NOT one-hotted print(&quot;loss:&quot;, loss.detach().numpy()) lost_step.append(loss) optimizer.zero_grad() # clear gradients for next train loss.backward() # backpropagation, compute gradients optimizer.step() # apply gradients 检验模型，计算准确率+画图 12345678910111213141516171819202122232425262728293031323334if t % 10 == 0: # plot and show learning process plt.cla() prediction = torch.max(out, 1)[1] print(prediction) pred_y = prediction.data.numpy() print(pred_y) target_y = y_train_V.data.numpy() # print(x) print(x_train_V.data.numpy()[:, 0]) x1_min, x1_max = x_train_V[:, 0].min(), x_train_V[:, 0].max() x2_min, x2_max = x_train_V[:, 1].min(), x_train_V[:, 1].max() plt.scatter(x_train_V.data.numpy()[:, 0], x_train_V.data.numpy()[:, 1], c=pred_y, s=100, lw=0, cmap='RdYlGn') # plt.legend() plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) y_test_pred = net(x_test_V.float()) prediction_y = torch.max(y_test_pred, 1)[1] pred_y_test = prediction_y.data.numpy() print(&quot;pred_y_test:&quot;, pred_y_test) y_test_target = y_test_V.data.numpy() print(&quot;y_test_target:&quot;, y_test_target) accuracy = float((pred_y_test == y_test_target).astype(int).sum()) / float(y_test_target.size) accyracy_list.append(accuracy) print(accuracy) plt.text(2.3, -1.5, 'Accuracy=%.2f' % accuracy, fontdict={'size': 15, 'color': 'red'}) plt.pause(0.1) 当lr = 0.2时 训练10次： 训练20次： 训练30次： 训练40次： 训练90次： 训练100次： 损失值与测试集准确率变化曲线 当lr = 0.5时 第10次训练： 第20次训练： 第30次训练： 第50次训练： 第100次训练： 损失值与测试集准确率变化曲线 动态更新学习率： 1optimizer = torch.optim.ASGD(net.parameters(), lr=0.5, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0) 第10次训练： 第20次训练： 第30次训练： 第100次训练： 损失值与测试集准确率变化曲线：","link":"/2021/07/31/%E5%9F%BA%E4%BA%8E%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9iris%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E7%B1%BB/"},{"title":"基于对抗网络生成数字图像","text":"基于生成对抗网络生成数字图像已知，采用卷积神经网络构建的生成对抗网络会比采用全连接网络的准确率高，所以会按照卷积网络、生成对抗网络、利用对抗网络生成数字图像的顺序进行介绍 参考资料： https://www.jianshu.com/p/1ea2949c0056 https://www.jianshu.com/p/fbcada37ca45 https://www.jianshu.com/p/77627ada2935 Convolutional Neural Networks (LeNet) - DeepLearning 0.1 documentation. DeepLearning 0.1. LISA Lab. [31 August 2013]. https://zhuanlan.zhihu.com/p/33752313 王坤峰，荀超，段艳杰等.生成式对抗网络GAN的研究进展与展望[J].自动化学报.2017 卷积神经网络卷积神经网络的理解： ​ 卷积神经网络的架构 全连接与稀疏连接假设一个神经网络中有m个输入、n个输出。那么对于全连接的矩阵相乘则需要mn个参数。如果输出的连接数被设定为j个，那么采用稀疏连接则只需要jn个参数。在许多情景中，在连接数被设定为j，且j比m要小得多的情况下，机器学习应用的速度获得大幅度的提升，并且仍然能保持较好的效果。 让我们从下图中对比一下全连接与稀疏连接的神经网络。 ​ 全连接的神经网络 ​ 稀疏连接的神经网络 稀疏连接的方法可以使神经网络的连接结构更加简单，同时以更高效的方法来描述变量之间的关系。对比上述两幅图，从输入的角度（自下而上）来看，x3输入在全连接中与所有的输出单元相连接。而在稀疏连接中x3仅仅与s2、s3、s4相连接。 ​ 自上而下从输出看输入 反过来从输出来看输入也是如此。 也许对于卷积网络，其稀疏连接方式的感受野无法设计整个输入，但是当卷积层数增加的时候（深层卷积网络）其单个输出的感受野还是可以涉及到整个输入的。 ​ 多层稀疏连接的感受野 卷积网络通过采用稀疏连接的方法减少了需要存储的参数（权重）的数量，减少了机器学习模型所需要的存储空间，从而提升了模型的统计效率。从计算方面来看，较少的参数数量意味着计算输出时需要更少的参数，从而计算效率也得到大幅提升。 参数共享参数共享是紧接着稀疏连接而来的。在模型中多个函数使用相同的参数则是参数共享。这个共享的参数通常是权重，即共享权重（Shared Weight）。在传统的神经网络中，每个权重被使用一次。而使用共享权重，一个输入位置的参数值也会被应用在其他的输入位置。在卷积网络中，通过参数共享，一个卷积核内的参数会被应用在输入的所有位置。 ​ 参数共享示意图 上图中黑色的箭头表示了在两个不同的模型中使用了特殊参数的连接。上图中，黑色箭头表示在卷积模型中对3个元素核的中间元素的使用。由于参数共享，因此这个单独的参数被用于所有的输入的位置。而在下图中，这个单独的黑色的箭头表示在全连接模型中对权重矩阵的中间元素的使用，下面这个模型没有参数共享，所以参数只使用了一次。 等变表示对于卷积来说，参数共享的特殊形式使得神经网络层具有了对平移等变（Equivariance）的性质。一个函数满足输入改变，那么输出也以同样的方式改变这一个性质，那么这个函数就是等变的。即输入发生变化输出也相应发生同样的变化。 如果f(g(x))=g(f(x))，那么函数f(x)对于变换g具有等变性。在卷积网络中，令g是输入的任意平移函数，那么卷积函数对于g具有等变性。举例，令I表示图像在整数坐标上的亮度函数，g表示图像函数的变换函数，即把一个图像映射到另一个图像函数的函数。令I’=g(I)，图像函数I’满足I’(x,y)=I(x-1,y)。上述函数所做的变换就是将I中的每一个像素均向右移动一个单位。如果先对图像I施加变换，再进行卷积操作f，结果等同于对图像I的卷积施加变换。也就是说，如果图像中的目标发生了一定的位移之后，卷积输出的表达也会产生相同的位移。这个特征对于作用在一个相对小区域的算子十分有用。 卷积网络的经典结构卷积网络的层结构简单的卷积神经网络由一系列不同的层构成，每个层将上一层的一组隐藏层的输出通过一个可微的函数产生一组新的隐藏层的输出。 一个典型的卷积网络有几种不同的层构成： 1、卷积层（Convolutional Layer，CONV） 2、ReLU（Rectified Linear Unit） ReLU(x)=max(0,x) 3、池化层（Pooling Layer，POOL） 4、全连接层（Fully-Connected Layer，FC） 全连接层与普通的神经网络相同。 这些层极其具体的作用如下表所示： 名称 作用 INPUT 输入层：如，以图像的像素的值作为输入 CONV 卷积层：卷积层连接输入的一小块区域，并计算卷积核与之对应的输入区域之间的点乘作为卷积层的输出 ReLU 激活函数：将CONV层中输出的每个元素通过一个非线性激活函数 POOL 池化层：在空间上（Height和Width）执行降采样操作 FC 全连接层：在分类中，将计算每个类别对应的分数，和传统神经网络一样，全连接层的每个神经元与前一层的所有输出相连 上述从INPUT到FC是一个典型的卷积网络的层结构。 CIFAR-10数据集共有60000张彩色图像，这些图像是32*32，分为10个类，每类6000张图。 ​ CIFAR-10数据集示例 以CIFAR-10数据集作为输入来讲解一下卷积网络的各个层的功能： 名称 作用 INPUT 输入层：输入一张大小为32323的3通道RGB图像 CONV 卷积层：如CONV层有12个卷积核，则通过CONV层输出的尺寸为323212 ReLU 激活函数：保持图像的尺寸为323212 POOL 池化层：以22的小窗做降采样操作，特征图的尺寸缩小到1616*12 FC 全连接层：在分类中，输出的尺寸为1110，也就是CIFAR-10中10个类别分别对应的分数 各种卷积网络的结构模式其实，目前很多的卷积网络都是根据一种层级结构的模式进行不同的堆叠。最常见的网络的结构是将 CONV-ReLU堆叠若干遍之后，紧接着一个POOL池化层。然后再重复上述的结构，直到图像在空间上转换成为一个较小的尺寸。最后使用一个全连接层转换为输出。 让我们以一个正则表达式来表示上述的模式： INPUT -&gt; [[CONV -&gt; RELU] * N -&gt; POOL ? ]M -&gt; [FC-&gt;RELU] * K -&gt; FC 其中， N代表重复N次，？代表0或1次，一般来说0&lt;N≤3，M≥0,0&lt;K≤3。 ​ VGGNet (2014) 卷积层的实现卷积层的参数有一组可以学习的卷积核(Kernel)/滤波器（Filter）构成。每个卷积核在空间上是尺寸较小，穿过输入集的整个深度，如下图所示： ​ 一个卷积网络的示意图 卷积网络的第一层的卷积核尺寸通常为333（宽3个像素 高3个像素 深度为通道数是3的RGB图像）或553。在前向传播的过程中，在输入图像上沿着高和宽的方向滑动各个卷积核/滤波器（滤波器是通过向量来表示对输入进行卷积操作的权重），并在所有的位置上面计算卷积核与输入的点乘。当完成沿着宽和高滑动卷积核之后，会得到一个二维的激活映射（Activation Map），这个激活映射也被称为特征映射（Feature Map）或是特征图。特征图的含义是其在每个空间位置上输入对于卷积核的响应。 ​ 滑动卷积核/滤波器得到特征映射 卷积层上的每个卷积核都会生成一个激活特征映射，将这些特征映射沿着深度的方向排列起来并作为卷积层的输出。 比如一个553的滤波器在32323的图像上沿着宽和高滑动，遍历空间内所有的点之后生成的特征图为28281。如果使用3个这样的滤波器/卷积核进行操作之后，将会生成3个28281的特征映射。所以卷积层最终的输出大小为28283。 通过3个滤波器得到的3层特征映射堆叠 在卷积网络中堆叠CONV-RELU这样的结构，卷积核/滤波器的深度要与输入的特征图的深度一致。也就是说，后一个卷积层的卷积核/滤波器大小需要与前一个卷积层输出的维度一致。 ​ 可视化卷积网络 通过观察上述卷积网络的特征图的输出，我们可以发现，随着网络的层数的不断加深，特征图上的响应在表达语义的层面上不断加深。最初的层提取了低层特征（Low-Level Feature），而此后的卷积层在低层特征的基础上产生了具有语义的图形和纹理。最后的卷积层对明确语义的目标产生强烈的响应，也就是说其抽取了图像的高层特征。 卷积层的空间排布在卷积网络中，输出的特征图的尺寸由深度（Depth）、步长（Stride）和零值填充（Zero-Padding）三个超参数决定。 对于输出图的深度这个超参数，其由使用的卷积核/滤波器的数量决定，每个卷积核都负责从输入图像中提取出不同的信息（见下图）。 ​ 不同的卷积操作对应的卷积核以及卷积输出 在卷积网络中对于同一个输入，为了提取不同的特征，需要使用不同的卷积核操作，并且将响应的特征映射堆叠排列起来作为输出。 然后就是滑动卷积核的步长。当滑动卷积核的步长为1的时候，卷积核/滤波器每次移动1个像素的位置。当步长为2的时候，卷积核每次移动2个像素的位置…步长越大，生成的特征映射的空间尺寸就越小。 最后是零值填充。有的时候，为了使用更深的卷积网络，此时则不希望特征映射在卷积的过程中尺寸下降地太快，因此会在输入的边缘使用零值填充来增大输入尺寸。 假设当前卷积层的输入图像尺寸为W、卷积神经元的感受野为F、步长S、边缘零值填充数量为P，则输出特征映射的尺寸为： ​ 经过卷积层的特征图尺寸 数据输入层该层要做的处理主要是对原始图像数据进行预处理，其中包括： 去均值：把输入数据各个维度都中心化为0，如下图所示，其目的就是把样本的中心拉回到坐标系原点上。 归一化：幅度归一化到同样的范围，如下所示，即减少各维度数据取值范围的差异而带来的干扰，比如，我们有两个维度的特征A和B，A范围是0到10，而B范围是0到10000，如果直接使用这两个特征是有问题的，好的做法就是归一化，即A和B的数据都变为0到1的范围。 PCA/白化：用PCA降维；白化是对数据各个特征轴上的幅度归一化 去均值与归一化效果图： 去相关与白化效果图： 把卷积层输出结果做非线性映射。 激活函数有： sigmoid：在两端斜率接近于0，梯度消失。 ReLu：修正线性单元，有可能出现斜率为0，但概率很小，因为mini-batch是一批样本损失求导之和。 TIPS: CNN慎用sigmoid！因为会映射到0-1，和图像的特征不太符合 首先试RELU，因为快，但要小心点。 如果RELU失效，请用 Leaky ReLU或者Maxout。 某些情况下tanh倒是有不错的结果，但是很少。 池化层也叫下采样层，具有特征不变性。 为了减少表达空间的尺寸，卷积网络的连续的卷积层之间往往会周期性地插入池化层。池化层能逐渐减少表达空间的尺寸，降低参数数量和计算开销，并控制卷积网络减少过拟合。 ​ 最大池化图解 在卷积网络中，最常见的池化操作是最大池化（Max Pooling），也就是取视野范围内的最大值。对上图最大池化示意图而言，其输入特征图的尺寸是44，步长为2的池化操作后，得到22的输出特征图。在池化窗口大小是2的是，上图中被分为四种颜色的四个区域，每个区域对应输出特征图的一个像素，对每个窗口取其中的最大值作为输出特征图相应位置的值。 池化窗口的选取通常是2或3，如果窗口大小过大则会对特征图的信息造成破坏。除了最大池化之外，还有平均池化（Average Pooling）和L2-Norm池化。 ​ 特征图池化操作输出的效果 最大池化操作的反向传播形式很简单：将梯度沿着正向传播的过程中最大值的路径向下传递。池化层的正向传递通常会保留最大激活单元下标，作为反向传递时候的传播路径。 CNN的优缺点优点： 共享卷积核，优化计算量。 无需手动选取特征，训练好权重，即得特征。 深层次的网络抽取图像信息丰富，表达效果好。 保持了层级网络结构。 不同层次有不同形式与功能。 缺点： 需要调参，需要大样本量，GPU等硬件依赖。 物理含义不明确。 与NLP/Speech共性： 都存在局部与整体的关系，由低层次的特征经过组合，组成高层次的特征，并且得到不同特征之间的空间相关性。 卷积神经网络之典型CNN结构 LeNet，这是最早用于数字识别的CNN AlexNet， 2012 ILSVRC比赛远超第2名的CNN，比 LeNet更深，用多层小卷积层叠加替换单大卷积层。 ZF Net， 2013 ILSVRC比赛冠军 GoogLeNet， 2014 ILSVRC比赛冠军 VGGNet， 2014 ILSVRC比赛中的模型，图像识别略差于GoogLeNet，但是在很多图像转化学习问题(比如object detection)上效果奇好 卷积神经网络常用的框架Caffe 源于Berkeley的主流CV工具包，支持C++,python,matlab Model Zoo中有大量预训练好的模型供使用 Torch Facebook用的卷积神经网络工具包 通过时域卷积的本地接口，使用非常直观 定义新网络层简单 TensorFlow Google的深度学习框架 TensorBoard可视化很方便 数据和模型并行化好，速度快. 生成对抗网络GANGAN的基本原理GAN 的核心思想来源于博弈论的纳什均衡。它设定参与游戏双方分别为一个生成器(Generator)和一个判别器 (Discriminator), 生成器的目的是尽量去学习真实的数据分布 ,而判别器的目的是尽量正确判别输入数据是来自真实数据还是来自生成器 ;为了取得游戏胜利 , 这两个游戏参与者需要不断优化 ,各自提高自己的生成能力和判别能力 ,这个学习优化过程就是寻找二者之间的一个纳什均衡。GAN的计算流程与结构如图 2 所示。任意可微分的函数都可以用来表示 GAN 的生成器和判别器 由此 ,我们用可微分函数D和 G来分别表示判别器和生成器 ,它们的输入分别为真实数据x和随机变量 z.G(z)则为由G 生成的尽量服从真实数据分布pdata的样本。如果判别器的输入来自真实数据 ,标注为1.如果输入样本为 G(z), 标注为 0. 这里 D 的目标是实现对数据来源的二分类判别 :真 ( 来源于真实数据x 的分布 )或者伪 ( 来源于生成器的伪数据 G(z)),而G的目标是使自己生成的伪数G(z)在D上的表现 D(G(z))和真实数据x在D上的表现 D(x)一致 ,这两个相互对抗并迭代优化的过程使得D和G 的性能不断提升 ,当最终D的判别能力提升到一定程度 ,并且无法正确判别数据来源时 ,可以认为这个生成器G已经学到了真实数据的分布。 手写字的例子来进行进一步窥探GAN的结构。 我们现在拥有大量的手写数字的数据集，我们希望通过GAN生成一些能够以假乱真的手写字图片。主要由如下两个部分组成： 定义一个模型来作为生成器（图中蓝色部分Generator），能够输入一个向量，输出手写数字大小的像素图像。 定义一个分类器来作为判别器（图三中红色部分Discriminator）用来判别图片是真的还是假的（或者说是来自数据集中的还是生成器中生成的），输入为手写图片，输出为判别图片的标签。 训练方法基本流程如下： 训练生成器之后达到（c）样本状态，此时生成器分布相比之前，逼近了真实样本分布。 经过多次反复训练迭代之后，最终希望能够达到（d）状态，生成样本分布拟合于真实样本分布，并且判别器分辨不出样本是生成的还是真实的（判别概率均为0.5）。也就是说我们这个时候就可以生成出非常真实的样本了，目的达到。 训练相关理论包含min，max的公式 判别器在这里是一种分类器，用于区分样本的真伪，因此我们常常使用交叉熵（cross entropy）来进行判别分布的相似性，交叉熵公式如下图所示： Tips: 公式中pi和qi为真实的样本分布和生成器的生成分布。由于交叉熵是非常常见的损失函数，这里默认大家都较为熟悉，就不进行赘述了。 在当前模型的情况下，判别器为一个二分类问题，因此可以对基本交叉熵进行更具体地展开如下图所示： Tips: 其中，假定y1为正确样本分布，那么对应的（1-y1）就是生成样本的分布。D表示判别器，则D(x1)表示判别样本为正确的概率，(1-D(x1)) 则对应着判别为错误样本的概率。这里仅仅是对当前情况下的交叉熵损失的具体化。相信大家也还是比较熟悉。 对于GAN中的样本点 xi ，对应于两个出处，要么来自于真实样本，要么来自于生成器生成的样本 x^ ~G(z) ( 这里的z是服从于投到生成器中噪声的分布)。 其中，对于来自于真实的样本，我们要判别为正确的分布 yi。来自于生成的样本我们要判别其为错误分布（1-yi）。将上面式子进一步使用概率分布的期望形式写出（为了表达无限的样本情况，相当于无限样本求和情况），并且让yi 为 1/2 且使用G(z)表示生成样本可以得到如下图的公式： 现在我们再回过头来对比原本的的minmax公式，发现他们其实就是同一个东西 生成数字图像采用的数据集因为GANS中超参数的设置非常非常麻烦，同样也需要很多的训练epoch。为了加快训练速度，这里使用MNIST数据集，拥有60，000个训练集和10，000测试集。每个图片中包含一个数字（0-9，背景为黑色，数字为白色）。这个数据集通过标准神经网络的训练已经可以达到超过99%的准确率。 这里使用pytorch中自带的数据集工具进行对数据的提取： 原始图像： 随机分布生成的噪声： 定义卷积判别网络： 定义卷积生成网络 定义损失函数 定义优化器 定义训练函数 实验结果： 早期： 最后的结果： 损失值： Iter: 250, D: 1.057, G:2.979 Iter: 500, D: 0.8309, G:1.727 Iter: 750, D: 0.918, G:1.692 Iter: 1000, D: 1.195, G:0.831 Iter: 1250, D: 0.9382, G:1.559 Iter: 1500, D: 1.344, G:1.697 Iter: 1750, D: 1.01, G:1.106 Iter: 2000, D: 1.214, G:1.769 Iter: 2250, D: 0.9676, G:1.234 Iter: 2500, D: 1.056, G:0.9057 Iter: 2750, D: 1.062, G:1.124 Iter: 3000, D: 1.158, G:0.8272 Iter: 3250, D: 0.9431, G:1.994 Iter: 3500, D: 1.112, G:1.288 Iter: 3750, D: 0.9812, G:0.9615 Iter: 4000, D: 1.125, G:1.248 Iter: 4250, D: 0.8623, G:1.461 Iter: 4500, D: 1.029, G:1.31 Iter: 4750, D: 0.8219, G:1.661 Iter: 5000, D: 0.9472, G:1.26 Iter: 5250, D: 0.9054, G:1.3 Iter: 5500, D: 0.8741, G:2.153 Iter: 5750, D: 0.9253, G:1.002 Iter: 6000, D: 0.9568, G:1.278 Iter: 6250, D: 0.9611, G:1.35 Iter: 6500, D: 0.8447, G:1.67 Iter: 6750, D: 0.9014, G:1.341 Iter: 7000, D: 0.9592, G:1.282 Iter: 7250, D: 0.985, G:1.329 Iter: 7500, D: 0.9468, G:1.517 Iter: 7750, D: 1.003, G:1.364 注：以上实验结果是已经得出的较优模型损失值等得出的较好结果 去掉卷积层，实现较为简单的生成对抗网络 改变网络结构为： 初始实验结果： 最终实验结果： 损失值： Iter: 250, D: 1.511, G:0.8354 Iter: 500, D: 1.359, G:0.612 Iter: 750, D: 1.389, G:2.019 Iter: 1000, D: 1.147, G:2.05 Iter: 1250, D: 0.833, G:2.16 Iter: 1500, D: 0.9256, G:1.52 Iter: 1750, D: 1.087, G:1.98 Iter: 2000, D: 0.9269, G:1.244 Iter: 2250, D: 1.108, G:1.061 Iter: 2500, D: 1.057, G:1.093 Iter: 2750, D: 1.115, G:1.932 Iter: 3000, D: 0.9873, G:1.402 Iter: 3250, D: 0.7824, G:1.464 Iter: 3500, D: 0.9784, G:1.319 Iter: 3750, D: 1.112, G:1.123 改变FC层网络结构为：（0&lt;K≤3。） 初始实验结果： 最终实验结果： 损失值： Iter: 250, D: 0.9404, G:1.127 Iter: 500, D: 0.8368, G:1.118 Iter: 750, D: 0.8559, G:0.8823 Iter: 1000, D: 1.018, G:1.133 Iter: 1250, D: 0.8485, G:1.997 Iter: 1500, D: 0.6933, G:1.756 Iter: 1750, D: 0.7199, G:1.98 Iter: 2000, D: 0.7108, G:1.534 Iter: 2250, D: 0.7834, G:2.019 Iter: 2500, D: 0.7777, G:1.758 Iter: 2750, D: 0.8702, G:1.776 Iter: 3000, D: 0.7444, G:1.677 Iter: 3250, D: 0.769, G:1.605 Iter: 3500, D: 1.103, G:1.76 Iter: 3750, D: 0.6795, G:2.354 Iter: 4000, D: 0.7162, G:1.787 Iter: 4250, D: 0.6472, G:2.09 Iter: 4500, D: 0.6834, G:2.19 Iter: 4750, D: 0.5053, G:2.736 Iter: 5000, D: 0.6162, G:2.434 Iter: 5250, D: 0.5765, G:3.15 Iter: 5500, D: 0.6916, G:2.053 Iter: 5750, D: 0.6257, G:2.553 Iter: 6000, D: 0.5586, G:2.937 Iter: 6250, D: 0.7283, G:2.733 Iter: 6500, D: 0.5604, G:3.598 Iter: 6750, D: 0.7311, G:1.48 Iter: 7000, D: 0.5016, G:3.57 Iter: 7250, D: 0.3809, G:3.069 Iter: 7500, D: 0.5193, G:2.837 更改模型的依据： GPU加速： 方法一：直接调用cuda()方法 12345678910real_data = Variable(x).cuda() *#* *真实数据*g_fake_seed = Variable(sample_noise).cuda()fake_images = G_net(g_fake_seed).cuda() *#* *生成的假的数据*D_DC = build_dc_classifier().cuda()for x, _ in train_data: X = X.cuda() 方法二：可以分别调用多块GPU 1234device = torch.device('cuda:0')X = X.to(device)net.to('cuda:0')b=torch.zeros(x.size(0),self.out_num_caps,self.in_num_caps).to('cuda:0')","link":"/2021/07/28/%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%94%9F%E6%88%90%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F/"},{"title":"python编程","text":"变量和简单类型单行注释和多行注释 通常而言，合理的代码注释应该占源代码的1/3左右 变量弱类型语言两个典型特征 变量无需声明即可直接赋值：对于一个不存在的变量赋值就相当于定义了一个新变量 变量的数据类型可以动态的改变：同一个变量可以一会被赋值整数值，一会为字符串 使用print函数输出变量1print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False) value 可以输出多个变量 sep=’|’ end=’ ‘ file ```pythonf = open(“hello.txt”, “w”)print(“hello,world!”, file=f)f.close()1234567891011121314+ flush参数用于控制输出缓存，一般保持为False，以获得较好的性能### 变量的命名规则+ 标识符可以由字母、数字、下划线(_)组成，其中数字不能打头+ 标识符不能为python关键字，但可以包含关键字+ 标识符不能包含空格### python 的关键字和内置函数```pythonimport keywordkeyword.kwlist 1dir(__builtins__) 数值类型整型整型数值的四种表示形式 十进制 二进制：0b或0B开头 八进制：0o或0O开头 十六进制：0x或0X开头 为了提高数值（包括浮点型）的可读性，python3允许使用_对数值进行分隔 123one_million = 1_000_000print(one_million)price = 234_234_234 # price实际的值为234234234 浮点型表示形式： 十进制形式 科学计数形式 5.12e2 5.12E2 –&gt; 5.12x102 注：只有浮点型数值才可以用科学计数形式表示。51200为整型，512E2为浮点型 复数复数的虚部用j或J表示 1import cmath 字符串字符串和转义字符123str = '&quot;hello,my girlfriend.Let's have dinner&quot;, he said.' # ×str = '&quot;hello,my girlfriend.Let\\'s have dinner&quot;, he said.' # √# 观察颜色 拼接字符串 两个字符串写在一起，自动拼接 12str = &quot;hello,&quot; &quot;girlfriend&quot;print(str) +号拼接 1234str1 = &quot;hello,&quot;str2 = &quot;girlfriend&quot;str3 = str1 + str2print(str3) repr和字符串当需要将字符串与数值进行拼接时，可以使用str()和repr()函数 12345s = &quot;这本书的价格是：&quot;price = 118print(s + p) # 报错print(s + str(p))print(s + repr(p)) 其中str是python内置的函数，repr则是函数，此外repr还可以以python表达式的形式来表示值 12345str = &quot;hello, my girlfriend&quot;print(str)print(repr(str))&gt;&gt;&gt; hello, my girlfriend&gt;&gt;&gt; 'hello, my girlfriend' 带引号的字符串——字符串的python的表达式形式 交互式解释器中，python会自动使用repr 使用input和raw_input获得用户输入input函数总是返回一个字符串 长字符串1234str = '''hello,mygirlfriendlet's have dinner''' 123str = &quot; \\hello,mygirlfriend \\let's have dinner&quot; 12num = 20 + 3 / 4 + \\ 2 * 3 原始字符串原始字符串以r开头，且不会把\\当成特殊字符 1234&gt;&gt;&gt; print('&quot;let\\'s go&quot;, she said')&quot;let's go&quot;, she said&gt;&gt;&gt; print(r'&quot;let\\'s go&quot;, she said')&quot;let\\'s go&quot;, she said 原始字符串的结尾不能为\\ 需要的话可以使用字符串拼接方法 字节串（bytes）字符串转换成bytes对象 字符串内容都为ASCII字符，可直接在字符串之前加ｂ 调用bytes()函数，如果不指定字符集，默认为utf-8 调用字符串本身的encode()方法 1234567891011121314151617181920212223242526272829&gt;&gt;&gt; b1 = bytes()&gt;&gt;&gt; b1b''&gt;&gt;&gt; b2 = b''&gt;&gt;&gt; b2b''&gt;&gt;&gt; b3 = b'helloworld'&gt;&gt;&gt; b3b'helloworld'&gt;&gt;&gt; b3[0]104&gt;&gt;&gt; b3[2:4]b'll&gt;&gt;&gt; b4 = b'你好世界'SyntaxError: bytes can only contain ASCII literal characters.&gt;&gt;&gt; b5 = bytes(&quot;helloworld&quot;, encoding = 'utf-8')&gt;&gt;&gt; b5b'helloworld'&gt;&gt;&gt; print(b5)b'helloworld'&gt;&gt;&gt; b6 = bytes(&quot;你好世界&quot;, encoding = 'utf-8')&gt;&gt;&gt; b6b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\\xe4\\xb8\\x96\\xe7\\x95\\x8c' &gt;&gt;&gt; b7 = &quot;你好世界&quot;.encode('utf-8')&gt;&gt;&gt; b7b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\\xe4\\xb8\\x96\\xe7\\x95\\x8c'&gt;&gt;&gt; st = b7.decode('utf-8')&gt;&gt;&gt; st'你好世界' 深入理解字符串转义字符 转义字符 说明 \\b 退格符 \\n 换行符 \\r 回车符 \\t 制表符 \\“ 双引号 \\‘ 单引号 \\\\ 反斜线 字符串格式化python提供了“%”对各种类型的数据进行格式化输出 12price = 118print(&quot;this book costs %s yuan&quot; % price) 123name = &quot;zhangsan&quot;price = 118print(&quot;%s 's book cost %s yuan&quot; % (name, price)) 转换说明符 说明 d, i 带符号十进制整数 o 带符号八进制整数 x 带符号十六进制整数 X 带符号十六进制整数 e 科学计数法的浮点数e E 科学计数法的浮点数E f, F 十进制的浮点数 g 智能选择f或e G 智能选择F或E C 转换为单字符 r repr()转换为字符串 s str()转换为字符串 12345678910111213num = 118print(&quot;num is %6i&quot; % num)print(&quot;num is %6d&quot; % num)print(&quot;num is %6o&quot; % num)print(&quot;num is %6x&quot; % num)print(&quot;num is %6X&quot; % num)print(&quot;num is %6s&quot; % num)&gt;&gt;&gt; num is 118&gt;&gt;&gt; num is 118&gt;&gt;&gt; num is 166&gt;&gt;&gt; num is 76&gt;&gt;&gt; num is 76&gt;&gt;&gt; num is 118 此时指定了字符串的最小宽度为6，默认情况下，转换出来的字符串总是右对齐的，在python中是可以改变的 -：指定左对齐 +：表示数值总要带着符号（正数带+，负数带-） 0：表示不补充空格，补充0 注：这三个标志可以同时存在 对于浮点数，python允许指定小数点后的数字位数 对于字符串，python允许指定转换后的字符串的最大字符数 123name = &quot;zhangsan&quot;print(&quot;kuangtu is %10.5s &quot; % name)&gt;&gt;&gt; kuangtu is zhang 序列相关方法12345s[3:-5]s[5:]s[-6:]s[:5]s[:-6] 12345s = 'helloworld'print('hello' in s)len()max()min() 大小写相关方法12&gt;&gt;&gt; dir(str)&gt;&gt;&gt; help(str.title) s.title() 首字母大写 s.upper() 每个字母大写 s.lower() 每个字母小写 删除空白strip v 脱衣服; 除去，剥去; 拆卸; 剥夺; strip() 方法用于移除字符串头尾指定的字符（默认为空格）。 strip()：删除字符串前后的空白 lstrip()：删除字符串前面（左边）的空白 rstrip()：删除字符串后面（右边）的空白 1234567&gt;&gt;&gt; help(str.strip)Help on method_descriptor:strip(self, chars=None, /) Return a copy of the string with leading and trailing whitespace removed. If chars is given and not None, remove characters in chars instead. python中str不可变，故返回副本而不是原字符串的改变 注意：该方法只能删除开头或是结尾的字符，不能删除中间部分的字符。 12345str = &quot;*****this is **string** example....wow!!!*****&quot;print (str.strip( '*' )) # 指定字符串 *&gt;&gt;&gt; this is **string** example....wow!!!str = &quot;123abcrunoob321&quot;print (str.strip( '12' )) # 字符序列为 12 查找、替换相关方法 startwith()：判断字符串是否以指定子串开头 endswith()：判断字符串是否以指定子串结尾 find()：查找指定子串在字符串中出现的位置，若没找到，返回-1 index()：查找指定子串在字符串中出现的位置，若没找到，引发ValueError错误 replace()：使用指定子串替换字符串中的目标子串 translate()：使用指定的翻译映射表对字符串替换 12345678910111213141516print(s.replace('hello', 'hi', 1))intab= &quot;aeiou&quot;outtab= &quot;12345&quot;deltab= &quot;thw&quot; trantab1= str.maketrans(intab,outtab)# 创建字符映射转换表trantab2= str.maketrans(intab,outtab,deltab)#创建字符映射转换表，并删除指定字符 test= &quot;this is string example....wow!!!&quot; print(test.translate(trantab1))print(test.translate(trantab2))&gt;&gt;&gt; th3s3s str3ng2x1mpl2....w4w!!!&gt;&gt;&gt; 3s 3s sr3ng2x1mpl2....4!!! 分割、连接方法 split()：将字符串按指定分隔符分割成多个短语 join()：将多个短语连接成字符串 123456789str = &quot;Line1-abcdef \\nLine2-abc \\nLine4-abcd&quot;;print str.split( ); # 以空格为分隔符，包含 \\nprint str.split(' ', 1 ); # 以空格为分隔符，分隔成两个['Line1-abcdef', 'Line2-abc', 'Line4-abcd']['Line1-abcdef', '\\nLine2-abc \\nLine4-abcd']message = 'https://mp.csdn.net/'print(message.split(&quot;//&quot;)[1].split(&quot;/&quot;)[0].split(&quot;.&quot;))打印结果：['mp', 'csdn', 'net'] 1234567891011121314s1 = &quot;-&quot;s2 = &quot;&quot;seq = (&quot;r&quot;, &quot;u&quot;, &quot;n&quot;, &quot;o&quot;, &quot;o&quot;, &quot;b&quot;) # 字符串序列print (s1.join( seq ))print (s2.join( seq ))r-u-n-o-o-brunoob&gt;&gt;&gt;li = ['my','name','is','bob'] &gt;&gt;&gt;' '.join(li) 'my name is bob' &gt;&gt;&gt;'_'.join(li) 'my_name_is_bob' 运算符赋值运算符算数运算符位运算符 &amp;：按位与 |：按位或 ^：按位异或 ~：按位取反 &lt;&lt;：左位移运算符 ‘&gt;&gt;：右位移运算符 扩展后的赋值运算符索引运算符[] [2:8:3] 比较运算符与bool类型 is：判断两个变量使用的对象是否相同 is not：判断两个变量使用的对象是否不相同，不相同返回Tru 12345import timea = time.gtime()b = time.gtime()print(a == b) # Trueprint(a is b) # False 每次调用gtime()函数都返回不同的对象 123id(a)id(b)# 判断变量所引用对象的内存地址，计算机同一块内存在任一时刻只能存放一个对象 逻辑运算符三目运算符1True_statements if expression else False_statements python允许在三目运算符的True_statements或False_statements中放置多条语句 多条语句以英文逗号隔开：每条都会执行，返回所有返回值构成的元组 多条语句以英文逗号隔开：每条都会执行，返回第一条语句的返回值 in运算符 in not in in运算符可以判断字符串是否包含特定的子串，和序列是否包含子序列 运算符的结合性和优先级列表、元组和字典序列简介python的序列…… 创建列表和元组…… 列表和元组的通用用法通过索引使用元素…… 子序列slice [start: end: step] 加法 列表只能和列表相加 元组只能和元组相加 元组不能直接和列表相加 乘法意义：列表或元组包含的元素重复N次 123456&gt;&gt;&gt; l = (&quot;ll&quot;)&gt;&gt;&gt; type(l)&lt;class 'str'&gt;&gt;&gt;&gt; l = (&quot;ll&quot;,)&gt;&gt;&gt; type(l)&lt;class 'tuple'&gt; in运算符…… 长度、最大值和最小值一次比较每个字符的ASCII码值 序列封包和序列解包 程序将多个值赋给一个变量时，python会自动将多个值封装成元组，此为封包 程序允许将序列（元组列表等）直接赋值给多个变量，此时序列中的各元素会被依次赋值给每个变量（要求个数相等），此为解包 1234567# 封包vals = 10, 20, 30# 解包a_tuple = tuple(range(1, 10, 2))a, b, c, d, e = a_tuplea_list = ['xsad', 'dsvsvf']a_str, b_str = a_list 12345x, y, z = 10, 20, 30# 执行过程如下：xyz = 10, 20, 30x, y, z = xyz 1x, y, z = y, z, x 程序的解包时可以只解出部分变量，剩下的依然使用列表变量保存 12345678910111213# first、second保存前两个元素，rest列表包含剩下的元素first, second, *rest = range(10)print(first) # 0print(second) # 1print(rest) # [2, 3, 4, 5, 6, 7, 8, 9]# last保存最后一个元素，begin保存前面剩下的begin, *last = range(10)print(begin) # [0, 1, 2, 3, 4, 5, 6, 7, 8]print(last) # 9# first保存第一个元素，last保存最后一个，middle保存中间剩下的print(first) # 0print(middle) # [0, 1, 2, 3, 4, 5, 6, 7, 8]print(last) # 9 使用列表创建列表list()函数 tuple()函数 增加列表元素 append()函数，会形成列表中嵌套列表，嵌套元组的情形 extent()函数，追加列表中的元素而不是将列表当做一个元素 insert()函数，指定位置插入元素 删除列表元素 del语句，可以删除列表元素及变量 根据索引 可以删除列表中单个元素，也可以删除列表的中间一段 ```pythondel a_list[1: 3] # 不包含del a_list[1: -1: 2] # 不包含，间隔为2 12345+ remove()函数，根据元素的本身，只删除第一个，找不到抛出ValueError - ```python c_list.remove('csdsv') clear()方法，清空列表中所有元素 ```pythonc_list.clear()12345678910111213141516171819### 修改列表元素+ 修改元素法增加、删除元素```pythonb_list = list(range(1, 5))print(b_list)# 将第2个到第4个（不包含）元素赋值为新列表的元素b_list[1: 3] = ['a', 'b']print(b_list) # [1, 'a', 'b', 4]# 将第3个到第3个（不包含）元素赋值为新列表的元素，就是插入元素b_list[2:2] = ['x', 'y']print(b_list) # [1, 'a', 'x', 'y', 'b', 4]# 将第3个到第6个（不包含）元素赋值为空列表，就是删除元素b_list[2: 5] = []print(b_list) # [1, 'a', 4] 使用slice语法赋值时，不能使用单个值，使用字符串赋值python会自动把字符串当成序列处理，其中每一个字符都是一个元素 slice语法赋值时，如果使用step参数，则元素个数要保持一致 列表中其他常用方法 count()：用于统计列表中某个元素出现的次数 index()：用于判断某个元素在列表中出现的位置 pop()：用于将列表当做“栈”使用，实现元素出栈功能 reverse()：用于将列表中的元素反向存放 sort()：用于对列表元素排序 使用字典创建字典元组可做key，列表不能，key要求为不可变的 使用dict()函数创建字典时，可以传入多个列表或元组参数作为key-value对 1234vegetables = [('celery', 1.58), ('brocoil', 1.29), ('lettuce', 2.19)]dict3 = dict(vegetables)cars = [['BWM', 8.5], ['bens', 8.3], ['AUDI', 7.9]]dict4 = dict(cars) 1dict5 = dict(spinach = 1.39, cabbage = 2.59) 字典的基本用法 通过key访问value 通过key添加key-value对 通过key删除key-value对 通过key修改key-value对 通过key判断指定key-value对是否存在 字典的常用方法 clear()：清空字典中所有key-value对 get()：根据key获取value，若不存在，直接访问报错，get方法None update()：存在覆盖，不存在更新 items()：获取字典中所有的key-value对 keys()：获取字典中所有的key values()：获取字典中所有的value 1234567891011&gt;&gt;&gt; cars = [['BWM', 8.5], ['bens', 8.3], ['AUDI', 7.9]]&gt;&gt;&gt; carss = dict(cars)&gt;&gt;&gt; itms = carss.items()&gt;&gt;&gt; print(itms)dict_items([('BWM', 8.5), ('bens', 8.3), ('AUDI', 7.9)])&gt;&gt;&gt; print(list(itms))[('BWM', 8.5), ('bens', 8.3), ('AUDI', 7.9)]&gt;&gt;&gt; print(list(carss.keys()))['BWM', 'bens', 'AUDI']&gt;&gt;&gt; print(list(carss.values()))[8.5, 8.3, 7.9] pop()：用于获取指定key对应的value并删去此key-value popitem()：随机弹出字典中的一个key-value（总是弹出底层存储的最后一个key-value）弹出格式为元组，可使用序列解包分别接受 1k, v = cars.popitem() setdefault()：default 默认的 根据key获取value，存在则直接返回，不存在则读取默认 fromkeys()：使用给定的多个key创建字典，value默认为None，也可以指定 使用字典格式化字符串1234# 在字符串模板中使用keytemp = '书名是：%(name)s，价格是%(price)010.2f，出版社是：%(publish)s'book = {'name':'疯狂python', 'price':118, 'publish':'地摊'}print(temp % book) 流程控制顺序结构…… if分支结构使用if else分支语句时，一定要先处理包含范围更小的情形 pass语句…… 断言断言语句与if分支有些类似，它用于对一个bool表达式进行断言，如果该表达式为True，该程序可以继续向下执行；否则抛出AssertionError异常。 1234s_age = input(&quot;请输入您的年龄：&quot;)age = int(s_age)assert 20 &lt; age &lt; 80print(&quot;输入的年龄在20和80之间&quot;) assert断言的逻辑： 12if 条件为False： 程序引发AssertionError异常 循环结构while循环…… while循环遍历…… for-in循环…… for-in循环遍历…… for-in循环遍历字典字典包含三种方法： items() keys() values() for-in循环遍历字典正是基于这三种方法读取的列表进行遍历 123456for key, value in my_dict.items(): passfor key in my_dict.keys(): print(my_dict[key])for value in my_dict.values(): pass 循环使用elsepython的循环都可以定义else代码块，当循环条件为False时，程序会执行else代码块 123456count_i = 0while count_i &lt; 5: print('count_i小于5：', count_i) count_i += 1else: print('count_i大于或等于5：', count_i) 这里else相当于print 12345count_i = 0while count_i &lt; 5: print('count_i小于5：', count_i) count_i += 1print('count_i大于或等于5：', count_i) 循环的else是为了使python代码更优雅 在for循环中，else可以读取循环计数器的最后一个值 12345a_list = [330, 54, 5.68, -56.2, 'dksoji', 'dsjk']for ele in a_list: print('元素：', ele)else: print('else块值：', ele) 嵌套循环…… for表达式 列表推导式 ```pythona_range = range(10)b_list = [x * x for x in a_range if x % 2 == 0]print(b_list)1234567891011+ 生成器推导式 - ```python a_range = range(10) c_generator = (x * x for x in a_range if x % 2 == 0) for i in c_generator: print(i, end='\\t') &gt;&gt;&gt; c_generator &lt;generator object &lt;genexpr&gt; at 0x00000231A888A6D0&gt; 多循环列表推导式 ```pythone_list = [(x, y, z) for x in range(5) for y in range(4) for z in range(6)]12345- ```python a_list = [5, 56, 89, 586, 2, 4898] b_list = [5, 8, 69, 4] c_list = [(x, y) for x in a_list for b in b_list if y % x == 0] 常用工具函数 zip()：将多个列表压缩成一个zip对象（可迭代对象），且以更短列表为准 reversed()： ```python[x for x in reversed(b)]123456+ sorted()： - ```python sorted(a, reverse = True) sorted(b, key=len) 控制循环结构使用break结束循环…… 使用continue忽略本次循环剩下的语句…… 使用return结束方法return直接结束整个函数或方法，而不管return处于多少层循环 函数和lambda表达式函数入门定义函数和调用函数…… 为函数提供文档将一段字符串放在函数声明之后、函数体之前，这段字符串将被作为函数的部分，这个文档就是函数的说明文档 可以通过help函数和 __doc__属性进行查看 1234567def func(): ''' hello world! ''' passhelp(func)print(func.__doc__) 多个返回值如果python函数直接返回多个值，python会自动将多个返回值封装成元组 此外，可以通过序列解包获取多个返回值 递归函数…… 函数的参数位置参数位置参数须以正确的顺序传入函数。调用时的数量必须和声明时的一样。 调用printme()函数，你必须传入一个参数，不然会出现语法错误： 12345678910#!/usr/bin/python3 #可写函数说明def printme( str ): &quot;打印任何传入的字符串&quot; print (str) return # 调用 printme 函数，不加参数会报错printme() 以上实例输出结果： 1234Traceback (most recent call last): File &quot;test.py&quot;, line 10, in &lt;module&gt; printme()TypeError: printme() missing 1 required positional argument: 'str' 关键字参数关键字参数和函数调用关系紧密，函数调用使用关键字参数来确定传入的参数值。 使用关键字参数允许函数调用时参数的顺序与声明时不一致，因为 Python 解释器能够用参数名匹配参数值。 以下实例在函数 printme() 调用时使用参数名： 12345678910#!/usr/bin/python3 #可写函数说明def printme( str ): &quot;打印任何传入的字符串&quot; print (str) return #调用printme函数printme( str = &quot;hello world&quot;) 以上实例输出结果： 1hello world 以下实例中演示了函数参数的使用不需要使用指定顺序： 1234567891011#!/usr/bin/python3 #可写函数说明def printinfo( name, age ): &quot;打印任何传入的字符串&quot; print (&quot;名字: &quot;, name) print (&quot;年龄: &quot;, age) return #调用printinfo函数printinfo( age=50, name=&quot;zhangsan&quot; ) 以上实例输出结果： 12名字: zhangsan年龄: 50 参数的默认值调用函数时，如果没有传递参数，则会使用默认参数。以下实例中如果没有传入 age 参数，则使用默认值 12345678910111213#!/usr/bin/python3 #可写函数说明def printinfo( name, age = 35 ): &quot;打印任何传入的字符串&quot; print (&quot;名字: &quot;, name) print (&quot;年龄: &quot;, age) return #调用printinfo函数printinfo( age=50, name=&quot;runoob&quot; )print (&quot;------------------------&quot;)printinfo( name=&quot;runoob&quot; ) 以上实例输出结果： 12345名字: runoob年龄: 50------------------------名字: runoob年龄: 35 未指定成为关键字参数的位置参数必须按照函数的定义位置顺序 关键字参数必须位于位置参数后面（调用和定义） 默认参数定义在形参列表后面 参数收集（个数可变的参数）可以在调用函数时传入任意多个参数 1234def functionname([formal_args,] *var_args_tuple ): &quot;函数_文档字符串&quot; function_suite return [expression] 加了星号 ***** 的参数会以元组(tuple)的形式导入，存放所有未命名的变量参数。 1234567891011#!/usr/bin/python3 # 可写函数说明def printinfo( arg1, *vartuple ): &quot;打印任何传入的参数&quot; print (&quot;输出: &quot;) print (arg1) print (vartuple) # 调用printinfo 函数printinfo( 70, 60, 50 ) 以上实例输出结果： 123输出: 70(60, 50) 如果在函数调用时没有指定参数，它就是一个空元组。我们也可以不向函数传递未命名的变量。如下实例： 1234567891011121314#!/usr/bin/python3 # 可写函数说明def printinfo( arg1, *vartuple ): &quot;打印任何传入的参数&quot; print (&quot;输出: &quot;) print (arg1) for var in vartuple: print (var) return # 调用printinfo 函数printinfo( 10 )printinfo( 70, 60, 50 ) 以上实例输出结果： 123456输出:10输出:706050 此外，python还可以收集关键字参数，在参数面前**表示， 一个函数可以同时包括一个支持“普通“参数收集的参数和一个支持关键字参数收集的参数 123456789101112#!/usr/bin/python3 # 可写函数说明def printinfo( arg1, *hello, **vardict ): &quot;打印任何传入的参数&quot; print (&quot;输出: &quot;) print (arg1) print (hello) print (vardict) # 调用printinfo 函数printinfo(1, &quot;你好&quot;, &quot;hi&quot;, a=2,b=3) 以上实例输出结果： 12345输出: 1你好hi{'a': 2, 'b': 3} 声明函数时，参数中星号 ***** 可以单独出现，例如: 12def f(a,b,*,c): return a+b+c 如果单独出现星号 ***** 后的参数必须用关键字传入。 123456789&gt;&gt;&gt; def f(a,b,*,c):... return a+b+c... &gt;&gt;&gt; f(1,2,3) # 报错Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: f() takes 2 positional arguments but 3 were given&gt;&gt;&gt; f(1,2,c=3) # 正常6 逆向参数收集逆向参数收集，是指在程序已有列表、元组、字典等对象的前提下，把它们的元素“拆开”后传给函数的参数 逆向参数收集需要在传入的列表、元组参数之前添加一个星号，在字典参数之前添加两个星号 123456def test(name, message): print('用户是：', name) print('欢迎消息：', message)my_list = ['孙悟空', '欢迎来到水帘洞']test(*my_list) 实际上，即使是支持收集的参数，如果程序需要将一个元组传给该参数，那么同样需要使用逆向收集，例如以下代码： 123456def foo(name, *nums): print('name参数:', name) print('nums参数:', nums)my_tuple = (1, 2, 3)foo('fkit', *my_tuple) 输出如下： 12name参数：fkitnums参数：（1，2，3） 使用逆向收集，my_tuple第一个元素传给name参数，剩下的传给nums参数 1foo(*my_tuple) 输出如下： 12name参数：1nums参数：（2，3） 如果不使用逆向收集，整个元组将作为一个参数 12345foo(my_tuple)#输出name参数：（1，2，3）nums参数：（） 字典也支持逆向收集，字典将会以关键字的形式传入。 123456def bar(book, price, desc): print(book, '这本书的价格是：', price) print('描述信息：', desc)my_dict = {'price':89, 'book':'疯狂python讲义', 'desc':'这是一本系统全面的python学习图书'}bar(**mydict) 函数的参数传递机制 在python函数中对参数直接使用“=”符号赋值没有用 如果让函数修改某些数据，可以封装成列表字典等可变对象，再作为参数传入函数 变量作用域 局部变量 全局变量 globals()：返回全局范围内所有变量组成的“变量字典” locals()：返回当前局部范围内所有变量组成的“变量字典” vars(object)：获取在指定对象范围内所有变量组成的“变量字典” locals()在全局范围内调用=globals() globals()生成的字典修改会改变全局变量本身，locals()字典修改不会改变局部变量本身 局部遮蔽全局变量的处理： 访问一下被遮蔽的全局变量 在函数中声明全局变量 1global name 局部函数当出现局部函数内的变量遮蔽它所在函数内的局部变量时，可以定义nonlocal 1nonlocal name 区别： global：声明全局变量 nonlocal：声明访问当前函数所在函数内的局部变量 函数的高级内容使用函数变量当把函数赋值给变量之后，接下来程序也可通过变量来调用函数 使用函数作为函数形参12345678def func_a(func, *args, **kwargs): print(func(*args, **kwargs))def func_b(*args): return argsif __name__ == '__main__': func_a(func_b, 1, 2, 3) 在代码中，将函数func_b作为函数func_a的参数传入，将函数func_b的参数以元组args传入，并在调用func_b时，作为func_b的参数。 运行结果： 1(1, 2, 3) 但是这里存在一个问题，但func_a和func_b需要同名的参数时，就会出现异常，如： 123456789def func_a(arg_a, func, **kwargs): print(arg_a) print(func(**kwargs))def func_b(arg_a): print(arg_a)if __name__ == '__main__': func_a(arg_a='Hello Python', func=func_b) 异常信息： 1TypeError: func_b() missing 1 required positional argument: 'arg_a' 虽然通过修改，手动将arg_a作为参数传入func中进行调用，可以正常运行，但这明显不符合设计初衷：在func_a中执行func(**kwargs)时，很可能并不知道func到底需要什么参数。换句话说，如果已经提前知道需要调用什么函数，那完全不必要把函数作为参数传入另一个函数并调用，直接调用函数即可。 123456789def func_a(arg_a, func, **kwargs): print(arg_a) func(arg_a=arg_a, **kwargs)def func_b(arg_a): print(arg_a)if __name__ == '__main__': func_a(arg_a='Hello Python', func=func_b) 当加入第三个函数，func_c，它不需要arg_a这个参数时，就会出现问题。 12345678910111213def func_a(arg_a, func, **kwargs): print(arg_a) func(arg_a=arg_a, **kwargs)def func_b(arg_a): print(arg_a)def func_c(): print('Hello World')if __name__ == '__main__': func_a(arg_a='Hello Python', func=func_b) func_a(arg_a='Hello Python', func=func_c) 异常结果： 1TypeError: func_c() got an unexpected keyword argument 'arg_a' 目前想到的解决办法是尽量避免func_a存在跟其他函数相同的参数，比如把func_a的arg_a参数改成func_a_arg_a。 12345678910111213def func_a(func_a_arg_a, func, **kwargs): print(func_a_arg_a) func(**kwargs)def func_b(arg_a): print(arg_a)def func_c(): print('Hello World')if __name__ == '__main__': func_a(func_a_arg_a='temp', arg_a='Hello Python', func=func_b) func_a(func_a_arg_a='temp', func=func_c) 使用函数作为返回值函数作为返回值高阶函数除了可以接收函数作为参数外，还可以把函数作为结果值返回。 12345678910111213141516171819202122def lazy_sum(*args): def sum(): ax=0 for n in args: ax = ax + n return ax return sumf = lazy_sum(1,2,3,4,5)print f# &lt;function sum at 0x02657770&gt;# lazy_sum(1,2,3,4,5)返回的是一个指向求和的函数的函数名。# 在调用lazy_sum(1,2,3,4,5)的时候，不立刻求和，而是根据后面代码的需要在计算。print f()# 15# 用f()调用求和函数，计算出结果。f1 = lazy_sum(1,2,3,4,5,6)f2 = lazy_sum(1,2,3,4,5,6)print f1 == f2# False# lazy_sum()每调用一次，都会返回一个独一无二的函数地址。 例中，lazy_sum中的内部函数sum引用了外部函数lazy_sum的参数和局部变量，当lazy_sum返回函数sum时，相关参数和变量已经保存在返回的函数sum中了。我们称这为 闭包。 注意到返回的函数在其定义内部引用了局部变量args，所以，当一个函数返回了一个函数后，其内部的局部变量还被新函数引用，所以，闭包用起来简单，实现起来可不容易。 另一个需要注意的问题是，返回的函数并没有立刻执行，而是直到调用了f()才执行。我们来看一个例子： 123456789101112131415def count(): fs = [] for i in range(1,4): def f(): return i*i fs.append(f) return fsf1, f2, f3 = count()print f1()print f2()print f3()# 9# 9# 9 结果全部都是9. 不是预期的1,4,9！ 遂在编辑器中不断更改并调试运行观察变量的变化过程： 12345678910111213141516171819# -*- coding: utf-8 -*-def count(): fs = [] for i in range(1,4): def f(): return i*i fs.append(f) return fs# f1, f2, f3 = count()#将上述代码分开写：f1 = count()f2 = count()f3 = count()print(f1())print(f2())print(f3()) 结果编译器报错： Traceback (most recent call last):File “***.py”, line 16, in print(f1())TypeError: ‘list’ object is not callable f1 = count()这条语句执行时，count()函数会先执行，并将结果fs（这是一个包含三个元素（值是三个不同函数）的list！）返还f1。所以f1()是将list当函数用，故报错！ f2 = count()和f3 = count()也是这个道理。 所以第一个要弄清楚的是 ：初始代码中的f1, f2, f3 = count()是将count() 中返回值（list）的三个元素（元素值是函数）分别赋值给f1,f2,f3!此时它们是函数！ 修改代码： 123456789101112131415161718# -*- coding: utf-8 -*-def count(): fs = [] for i in range(1,4): def f(): return i*i fs.append(f) return fs# f1, f2, f3 = count()f1 = count()f2 = count()f3 = count()print(f1[0]())print(f2[0]())print(f3[0]()) 结果仍然是： 9 9 9 因为f1[0]()中存放的就是函数f, 但此时i是3，故返回输出9！ 所以返回闭包时牢记一点：返回函数不要引用任何循环变量，或者后续会发生变化的变量。 网上例子，有稍许啰嗦 局部函数与lambda表达式回顾局部函数…… 使用lambda表达式代替局部函数1lambda [parameter_list]: 表达式 lambda表达式必须使用lambda关键字定义 在lambda关键字后，冒号左边是参数列表，可以没有参数，也可以有多个参数，逗号隔开，冒号右边是lambda表达式的返回值 用途： 单行函数，省去了定义函数的过程，代码更加简洁 对于不需要多次使用的函数，lambda使用完后可以立即释放，提高了性能 类和对象","link":"/2021/08/01/python%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"技巧","slug":"技巧","link":"/tags/%E6%8A%80%E5%B7%A7/"},{"name":"深度学习","slug":"深度学习","link":"/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"前馈神经网络","slug":"前馈神经网络","link":"/tags/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"CNN","slug":"CNN","link":"/tags/CNN/"},{"name":"python","slug":"python","link":"/tags/python/"}],"categories":[{"name":"转载","slug":"转载","link":"/categories/%E8%BD%AC%E8%BD%BD/"},{"name":"智能科技","slug":"智能科技","link":"/categories/%E6%99%BA%E8%83%BD%E7%A7%91%E6%8A%80/"},{"name":"编程语言","slug":"编程语言","link":"/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"python","slug":"编程语言/python","link":"/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/python/"}]}